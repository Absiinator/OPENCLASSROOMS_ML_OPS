# üè¶ Home Credit Scoring - Projet MLOps Complet

[![CI/CD - Tests & Build](https://github.com/Absiinator/OPENCLASSROOMS_ML_OPS/actions/workflows/ci-cd.yml/badge.svg)](https://github.com/Absiinator/OPENCLASSROOMS_ML_OPS/actions/workflows/ci-cd.yml)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## üìã Description

Projet complet de **scoring de cr√©dit** bas√© sur le dataset [Home Credit Default Risk](https://www.kaggle.com/c/home-credit-default-risk) de Kaggle. Ce projet met en ≈ìuvre les meilleures pratiques **MLOps** pour construire, d√©ployer et monitorer un mod√®le de Machine Learning en production.

### üéØ Objectif m√©tier

Pr√©dire la **probabilit√© de d√©faut de paiement** d'un client demandant un cr√©dit, en optimisant le co√ªt m√©tier avec :
- **Co√ªt d'un Faux N√©gatif (FN)** : 10 (accepter un client qui fera d√©faut)
- **Co√ªt d'un Faux Positif (FP)** : 1 (refuser un bon client)

## üìö Documentation

| Document | Description |
|----------|-------------|
| [README.md](README.md) | Ce fichier - Vue d'ensemble du projet |
| [RENDER_SETUP.md](RENDER_SETUP.md) | Guide complet de d√©ploiement sur Render (API, Dashboard, MLflow) |
| [api/README.md](api/README.md) | README sp√©cifique de l‚ÄôAPI (objectif, endpoints, artefacts) |
| [streamlit_app/README.md](streamlit_app/README.md) | README sp√©cifique du dashboard Streamlit |
| [mlflow/README.md](mlflow/README.md) | README sp√©cifique du service MLflow |
| [tests/README.md](tests/README.md) | Documentation des tests unitaires et d'int√©gration |
| [presentation_outline.txt](presentation_outline.txt) | Plan de pr√©sentation - Phase 1 (MLOps) |
| [presentation_outline_phase2.txt](presentation_outline_phase2.txt) | Plan de pr√©sentation - Phase 2 (Dashboard + Veille) |

## üèóÔ∏è Architecture du projet

```
home-credit-scoring/
‚îú‚îÄ‚îÄ üìÅ api/                     # API FastAPI de scoring (Dockerfile inclus)
‚îú‚îÄ‚îÄ üìÅ mlflow/                  # Service MLflow UI (Dockerfile + README)
‚îú‚îÄ‚îÄ üìÅ streamlit_app/           # Dashboard Streamlit (Dockerfile inclus)
‚îú‚îÄ‚îÄ üìÅ models/                  # Mod√®les entra√Æn√©s (track√©s, sans Git LFS)
‚îú‚îÄ‚îÄ üìÅ data/                    # Fichiers CSV locaux (optionnels en d√©ploiement)
‚îú‚îÄ‚îÄ üìÅ notebooks/               # Notebooks + tracking MLflow (notebooks/mlruns)
‚îú‚îÄ‚îÄ üìÅ reports/                 # Rapports Evidently + figures
‚îú‚îÄ‚îÄ üìÅ src/                     # Code source (pr√©traitement, entra√Ænement, metrics)
‚îú‚îÄ‚îÄ üìÅ tests/                   # Tests unitaires
‚îú‚îÄ‚îÄ render.yaml                 # Blueprint Render (3 services)
‚îú‚îÄ‚îÄ run.py                      # Lancement local (API/Dashboard/MLflow)
‚îî‚îÄ‚îÄ README.md                   # Ce fichier
```

## üöÄ D√©marrage rapide

### Pr√©requis

- Python 3.10+
- Conda ou pip
- Docker (optionnel, pour le d√©ploiement)
- Compte Kaggle (pour les donn√©es)

### Installation locale

- Python 3.10+ requis
- D√©pendances d√©crites dans `environment.yml`, `pyproject.toml` et `api/requirements.txt`
- Le script `run.py` orchestre les services en local (API, Dashboard, MLflow)

### Donn√©es (local vs d√©ploiement)

- En local, les CSV sont attendus dans `data/`
- En d√©ploiement (Docker/Render), les images t√©l√©chargent et extraient automatiquement le dataset dans `/app/data`, sans Git LFS

### Entra√Ænement et tracking

- Le notebook `03_Model_Training_MLflow.ipynb` logge les runs MLflow dans `notebooks/mlruns/`
- Les mod√®les export√©s sont versionn√©s dans `models/` et utilis√©s par l‚ÄôAPI pour l‚Äôinf√©rence

### Lancement local

`run.py` expose les commandes `train`, `api`, `dashboard`, `mlflow`, `all` (ports par d√©faut ci‚Äëdessous).

### Ports par d√©faut

| Service | Port | URL |
|---------|------|-----|
| API FastAPI | 8000 | http://localhost:8000 |
| Dashboard Streamlit | 8501 | http://localhost:8501 |
| MLflow UI | 5002 | http://localhost:5002 |

*En d√©ploiement Docker/Render, MLflow √©coute sur le port 5000 (voir `render.yaml`).*

### Lancer avec Docker

Le projet fournit **3 Dockerfiles** (API, Dashboard, MLflow). Chaque image est pr√™te pour le d√©ploiement sur Render (plan gratuit).

#### 1. API (api/Dockerfile)
- **Port** : 8000
- **Contenu** :
  - Mod√®le LightGBM, pr√©processeur et configuration **track√©s dans `models/`**
  - Code API FastAPI + modules `src/`
  - Rapports Evidently (`reports/`) pour l‚Äôendpoint `/data/drift`
  - **Donn√©es t√©l√©charg√©es automatiquement** pendant le build (extraction vers `/app/data`)

#### 2. Dashboard (streamlit_app/Dockerfile)
- **Port** : 8501
- **Variables obligatoires** : `API_URL`, `MLFLOW_URL`
- **Contenu** :
  - Application Streamlit (Scoring + Comparaison int√©gr√©e, Data Drift, Documentation)
  - Rapports Evidently dans `reports/`
  - **Donn√©es t√©l√©charg√©es automatiquement** pendant le build (extraction vers `/app/data`)

#### 3. MLflow (mlflow/Dockerfile)
- **Port** : 5000
- **Contenu** :
  - MLflow UI avec runs copi√©s depuis `notebooks/mlruns/`
  - Registry MLflow disponible (lecture seule en production)

> üìù **Notes** :
> - Les **donn√©es sont t√©l√©charg√©es au build** des images API et Dashboard (pas de Git LFS).
> - **MLflow** est configur√© pour le plan gratuit (1 worker Gunicorn, m√©moire limit√©e).

## üìä R√©sultats du mod√®le

| M√©trique | Valeur |
|----------|--------|
| AUC-ROC | ~0.76 |
| Seuil optimal | ~0.35 |
| Accuracy | ~0.70 |
| Co√ªt m√©tier normalis√© | Optimis√© |

## üîß Fonctionnalit√©s principales

### 1. üìà Pr√©traitement avanc√©

- Agr√©gation des tables auxiliaires (bureau, previous_application, etc.)
- Feature engineering (ratios financiers, agr√©gats temporels)
- Gestion des valeurs manquantes
- Encodage des variables cat√©gorielles

### 2. üß† Mod√©lisation

- **LightGBM** avec class_weight='balanced'
- Optimisation du seuil de d√©cision via le co√ªt m√©tier
- Cross-validation stratifi√©e
- Logging complet avec MLflow

### 3. üîç Explicabilit√©

- **SHAP** pour les explications locales et globales
- Feature importance int√©gr√©e
- Visualisations interactives

### 4. üìâ Monitoring du drift

- Rapports **Evidently** automatis√©s
- D√©tection du data drift et prediction drift
- Alertes sur la d√©rive des features

### 5. üåê API REST (Pydantic v2 compatible)

| Endpoint | M√©thode | Description |
|----------|---------|-------------|
| `/` | GET | Page d'accueil |
| `/health` | GET | Health check (v√©rifie que les mod√®les sont charg√©s) |
| `/predict` | POST | Pr√©diction unique - **Supporte 3 formats JSON** |
| `/predict/batch` | POST | Pr√©dictions en batch |
| `/predict/explain` | POST | Pr√©diction + SHAP |
| `/model/info` | GET | Infos du mod√®le (seuil, version, features) |
| `/model/features` | GET | Liste des features |

**Format support√© pour `/predict`** :

```json
{
  "features": {
    "AMT_INCOME_TOTAL": 150000,
    "AMT_CREDIT": 500000,
    "DAYS_BIRTH": -18000
  }
}
```

**Notes** :
- L'API charge automatiquement les mod√®les au d√©marrage depuis `/app/models/` dans Docker.
- Seul le champ `features` est trait√©.

### 6. üîÑ CI/CD & D√©ploiement Render (plan gratuit)

- `render.yaml` d√©crit les 3 services (API, Dashboard, MLflow)
- Render **construit les images depuis les Dockerfiles** du repo
- `autoDeploy: true` active le d√©ploiement automatique √† chaque push
- Le workflow GitHub Actions (pr√©sent dans `.github/workflows/ci-cd.yml`) reste **optionnel** : il build/push des images GHCR, mais Render n‚Äôen d√©pend pas

Pour le guide complet de d√©ploiement, consultez [RENDER_SETUP.md](RENDER_SETUP.md).

## üìÅ Donn√©es

### üì¶ Fichiers suivis dans le repo (sans Git LFS)

- `models/` : artefacts n√©cessaires √† l‚Äôinf√©rence (API)
- `notebooks/mlruns/` : runs MLflow + registry (lecture seule en prod)
- `reports/` : rapports Evidently utilis√©s par le dashboard
- `data/` : utile en local, **non requis** en d√©ploiement (download au build)

Le projet utilise les donn√©es du challenge Kaggle [Home Credit Default Risk](https://www.kaggle.com/c/home-credit-default-risk) :

| Fichier | Description |
|---------|-------------|
| `application_train.csv` | Demandes de cr√©dit (entra√Ænement) avec TARGET |
| `application_test.csv` | Demandes de cr√©dit (test) |
| `bureau.csv` | Cr√©dits ant√©rieurs chez d'autres institutions |
| `bureau_balance.csv` | Historique mensuel des cr√©dits bureau |
| `previous_application.csv` | Demandes ant√©rieures chez Home Credit |
| `POS_CASH_balance.csv` | Historique des pr√™ts point de vente |
| `credit_card_balance.csv` | Historique des cartes de cr√©dit |
| `installments_payments.csv` | Historique des paiements |

### Pipeline de Traitement des Donn√©es

Le mod√®le a √©t√© entra√Æn√© sur **245+ features engineered**, mais l'API accepte des requ√™tes avec seulement **17 features brutes**. La transformation est **automatique** :

```
Dashboard/API (17 features)
    ‚Üì
create_application_features()  [ratios, moyennes, conversions]
    ‚Üì
CreditScoringPreprocessor.transform() [imputation, encoding]
    ‚Üì
LightGBM Model (245 features)
```

**17 Features requises :**
- **Finances** : `AMT_INCOME_TOTAL`, `AMT_CREDIT`, `AMT_ANNUITY`, `AMT_GOODS_PRICE`
- **Temporel** : `DAYS_BIRTH`, `DAYS_EMPLOYED`
- **Personnel** : `CNT_CHILDREN`, `CODE_GENDER_M`, `FLAG_OWN_CAR`, `FLAG_OWN_REALTY`
- **Scores** : `EXT_SOURCE_1`, `EXT_SOURCE_2`, `EXT_SOURCE_3`, `REGION_RATING_CLIENT`
- **Ratios** : `CREDIT_INCOME_RATIO`, `ANNUITY_INCOME_RATIO`, `EXT_SOURCE_MEAN`

**Gestion automatique :**
- ‚úÖ Features engineered ajout√©es dynamiquement
- ‚úÖ ~200 colonnes d'agr√©gation imput√©es avec la m√©diane apprises lors de l'entra√Ænement
- ‚úÖ Encodage des cat√©gorielles
- ‚úÖ Aucune configuration manuelle n√©cessaire

## üß™ Tests

La structure et les conventions de tests sont d√©crites dans `tests/README.md`.
Les tests sont con√ßus pour √™tre rapides en CI/CD et couvrent le co√ªt m√©tier,
le pr√©traitement et l‚ÄôAPI (pas de tests de d√©ploiement Render).

## ÔøΩ Versions Critiques - Pydantic v2

### Compatibilit√© Pydantic v2

L'API utilise **Pydantic v2.5+** avec un format unique pour les requ√™tes :

```python
# api/models.py
from pydantic import BaseModel, Field
from typing import Dict, Any

class PredictionRequest(BaseModel):
    features: Dict[str, Any] = Field(..., description="Features du client")
```

**Pourquoi cette approche ?**
- ‚úÖ Sch√©ma OpenAPI simple et explicite
- ‚úÖ √âvite les erreurs de format c√¥t√© client
- ‚úÖ Compatible avec le dashboard Streamlit

### Table de versions

| D√©pendance | Version | Raison |
|-----------|---------|--------|
| **Pydantic** | >=2.5.0,<3.0.0 | Compatibilit√© ConfigDict + Optional fields |
| **FastAPI** | >=0.104.0,<0.116.0 | Compatibilit√© Pydantic v2.5+ |
| **MLflow** | 2.9.2 | L√©ger (~50MB) vs versions r√©centes (~200MB+) |
| **Python** | 3.10+ | tomli conditionnel pour pyproject.toml (Python < 3.11) |

‚ö†Ô∏è **Si vous updatez ces versions, testez localement d'abord !** Les changements Pydantic v3 pourraient casser la validation.

## üîÅ CI/CD et D√©ploiement

### CI/CD (optionnel)

Le workflow GitHub Actions (`.github/workflows/ci-cd.yml`) ex√©cute :
- **Lint** (black, isort, flake8)
- **Tests unitaires** (pytest)
- **Build d‚Äôimages Docker** (API, Dashboard, MLflow) et push vers GHCR

‚ö†Ô∏è Render n‚Äôa pas besoin de GHCR si vous utilisez `render.yaml` : il build directement depuis le repo.

### Configuration Render (render.yaml)

Le fichier `render.yaml` d√©crit **3 services Docker** en plan gratuit :

| Service | Nom par d√©faut | Port | Health Check | Variables cl√©s |
|---------|----------------|------|--------------|----------------|
| **API** | `home-scoring-api` | 8000 | `/health` | `PORT`, `PYTHONPATH`, `HOST` |
| **Dashboard** | `home-scoring-dashboard` | 8501 | `/_stcore/health` | `PORT`, `API_URL`, `MLFLOW_URL` |
| **MLflow** | `home-scoring-mlflow` | 5000 | `/` | `PORT` |

**Point cl√©** : `API_URL` et `MLFLOW_URL` doivent correspondre aux URLs r√©elles des services Render.  
Si vous renommez les services, adaptez ces variables dans `render.yaml`.

### Variables d'environnement (r√©f√©rence)

| Variable | Service | Description | Valeur par d√©faut |
|----------|---------|-------------|-------------------|
| `HOST` | API | Host d‚Äô√©coute | `0.0.0.0` |
| `PORT` | API/Dashboard/MLflow | Port d‚Äô√©coute | 8000 / 8501 / 5000 |
| `PYTHONPATH` | API | Chemin Python | `/app` |
| `API_URL` | Dashboard | URL de l‚ÄôAPI | URL Render de l‚ÄôAPI |
| `MLFLOW_URL` | Dashboard | URL MLflow UI | URL Render MLflow |
| `STREAMLIT_SERVER_ADDRESS` | Dashboard | Adresse Streamlit | `0.0.0.0` |
| `STREAMLIT_SERVER_PORT` | Dashboard | Port Streamlit | `8501` |
| `MLFLOW_TRACKING_URI` | MLflow | Backend store | `/app/mlruns` |

## üìñ Documentation API

La documentation interactive est disponible via :
- **Swagger UI** : `http://localhost:8000/docs` - Tests des endpoints directement
- **ReDoc** : `http://localhost:8000/redoc` - Documentation compl√®te

### Exemple de payload (17 features minimal)

```json
{
  "features": {
    "AMT_INCOME_TOTAL": 150000,
    "AMT_CREDIT": 500000,
    "AMT_ANNUITY": 25000,
    "AMT_GOODS_PRICE": 500000,
    "DAYS_BIRTH": -12000,
    "DAYS_EMPLOYED": -5000,
    "CNT_CHILDREN": 1,
    "CODE_GENDER_M": 1,
    "FLAG_OWN_CAR": 1,
    "FLAG_OWN_REALTY": 1,
    "EXT_SOURCE_1": 0.5,
    "EXT_SOURCE_2": 0.6,
    "EXT_SOURCE_3": 0.55,
    "REGION_RATING_CLIENT": 2,
    "CREDIT_INCOME_RATIO": 3.33,
    "ANNUITY_INCOME_RATIO": 0.167,
    "EXT_SOURCE_MEAN": 0.55
  }
}
```

### Exemple de r√©ponse

```json
{
  "client_id": null,
  "probability": 0.23,
  "prediction": 0,
  "decision": "ACCEPTED",
  "risk_category": "low",
  "threshold": 0.44
}
```

### Notes importantes

- ‚úÖ **L'API accepte 17+ features** - Toutes les colonnes suppl√©mentaires sont ignor√©es (mode `extra="allow"`)
- ‚úÖ **Colonnes manquantes combl√©es automatiquement** - Les ~200 colonnes d'agr√©gation sont imput√©es avec la m√©diane
- ‚úÖ **Feature engineering automatique** - Ratios, moyennes et conversions cr√©√©s automatiquement
- ‚úÖ **Format JSON unique** - Accepte uniquement `{"features": {...}}`
- ‚ö†Ô∏è **Seuil par d√©faut : 0.44** - Optimis√© pour minimiser le co√ªt m√©tier (FN=10, FP=1)

## üêõ Probl√®mes Courants

### Erreur 422 "Field required" sur `/predict`

**Cause** : Incompatibilit√© Pydantic v2 avec les champs optionnels mal configur√©s

**Solution** : V√©rifiez que vous utilisez `Pydantic>=2.5.0` et envoyez le JSON avec le format correct :

```json
{"features": {"AMT_INCOME_TOTAL": 150000, "AMT_CREDIT": 500000, ...}}
```

Consulter [Versions Critiques - Pydantic v2](#-versions-critiques---pydantic-v2) pour les d√©tails.

### MLflow crashing avec "Out of Memory" ou "SIGKILL" sur Render

**Cause** : trop de workers Gunicorn ou d√©pendances lourdes sur un plan 512MB.

**Solution** : le Dockerfile utilise **`mlflow server` avec 1 worker** + d√©pendances minimales.

**V√©rification** : voir [mlflow/Dockerfile](mlflow/Dockerfile) et [mlflow/README.md](mlflow/README.md)

| Configuration | RAM | Status |
|---------------|-----|--------|
| **mlflow server --workers=1** (actuel) | ~200-250 MB | ‚úÖ Fonctionne |
| mlflow server (d√©faut 4 workers) | ~400-500 MB | ‚ùå CRASH |

### Dashboard ne peut pas se connecter √† l'API

**Cause** : Variables d'environnement `API_URL` ou `MLFLOW_URL` non configur√©es

**Solution (Render)** :
1. Allez sur le service **home-scoring-dashboard**
2. **Environment** ‚Üí Ajouter/modifier :
   - `API_URL=https://home-scoring-api.onrender.com`
   - `MLFLOW_URL=https://home-scoring-mlflow.onrender.com`
3. Red√©marrer le service (Deploy ‚Üí Select Commit ‚Üí Deploy)

**Solution (Local)** :
```bash
export API_URL=http://localhost:8000
export MLFLOW_URL=http://localhost:5000
streamlit run streamlit_app/app.py
```

## ü§ù Contribution

Les contributions sont les bienvenues :

1. Forker le repository
2. Cr√©er une branche d√©di√©e
3. Proposer les changements via Pull Request

## üìÑ Licence

Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de d√©tails.

## üìß Contact

Pour toute question ou suggestion, n'h√©sitez pas √† ouvrir une issue sur GitHub.

---

**R√©alis√© dans le cadre du projet OpenClassrooms "R√©alisez un dashboard et assurez une veille technique"**
