# Guide de Configuration Render pour DÃ©ploiement

Ce guide explique le dÃ©ploiement des 3 services sur Render.

## ğŸ—ï¸ Architecture CI/CD

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        GITHUB ACTIONS                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Tests       â”‚ -> â”‚ Build       â”‚ -> â”‚ Push vers GHCR      â”‚ â”‚
â”‚  â”‚ unitaires   â”‚    â”‚ Docker      â”‚    â”‚ (images publiques)  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          RENDER                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Pull images â”‚ -> â”‚ Injection   â”‚ -> â”‚ DÃ©ploiement         â”‚ â”‚
â”‚  â”‚ depuis GHCR â”‚    â”‚ variables   â”‚    â”‚ 3 services          â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**SÃ©paration des responsabilitÃ©s :**
- **GitHub Actions** : Tests unitaires + Build des images Docker + Push vers GHCR
- **Render** : DÃ©ploiement des services + Injection des variables d'environnement

## ğŸ“‹ PrÃ©requis

1. **Compte Render** : CrÃ©ez un compte gratuit sur [render.com](https://render.com)
2. **Compte GitHub** : Votre repo doit Ãªtre sur GitHub (dÃ©jÃ  fait âœ…)
3. **Images Docker** : Les images seront dans GitHub Container Registry (GHCR)

## ğŸ—ï¸ Architecture Docker

Le projet utilise 3 Dockerfiles distincts pour les 3 services :

### API (`api/Dockerfile`)

- **Base** : `python:3.10-slim`
- **Port** : 8000
- **Contenu** :
  - Code source (`src/`, `api/`)
  - âœ… **ModÃ¨les prÃ©-entraÃ®nÃ©s inclus** (`models/lgbm_model.joblib`, `preprocessor.joblib`, `model_config.json`)
  - âœ… **DonnÃ©es tÃ©lÃ©chargÃ©es automatiquement** depuis S3 OpenClassrooms lors du build
  - DÃ©pendances Python pour FastAPI, LightGBM, SHAP
- **TÃ©lÃ©chargement des donnÃ©es** : Le Dockerfile tÃ©lÃ©charge et dÃ©compresse automatiquement les donnÃ©es depuis :
  ```
  https://s3-eu-west-1.amazonaws.com/static.oc-static.com/.../home-credit-default-risk.zip
  ```
- **Health check** : `/health` (vÃ©rifie que les modÃ¨les sont chargÃ©s)
- **Commande** : `uvicorn api.main:app --host 0.0.0.0 --port $PORT`

### Dashboard (`streamlit_app/Dockerfile`)

- **Base** : `python:3.10-slim`
- **Port** : 8501
- **Contenu** :
  - App Streamlit (`app.py`) avec 5 onglets (ğŸ¯ Scoring, ğŸ“Š Comparaison, ğŸ“ Import/Simulation, ğŸ“ˆ Drift, ğŸ“– Documentation)
  - Sources (`src/`)
  - âœ… **DonnÃ©es tÃ©lÃ©chargÃ©es automatiquement** depuis S3 OpenClassrooms lors du build
- **Health check** : `/_stcore/health`
- **Commande** : `streamlit run app.py --server.port=$PORT`

### MLflow (`mlflow/Dockerfile`)

- **Base** : `python:3.10-slim`
- **Port** : 5000
- **Contenu** : RÃ©pertoire `notebooks/mlruns/` copiÃ© dans l'image avec correction automatique des chemins
- **Commande** : `mlflow ui --host 0.0.0.0 --port $PORT --backend-store-uri /app/mlruns`

âš ï¸ **Notes importantes** :

- Les **donnÃ©es sont tÃ©lÃ©chargÃ©es automatiquement** lors du build Docker (~500MB)
- **MLflow** : Les runs/experiments sont copiÃ©s en lecture seule depuis `notebooks/mlruns/`

## ğŸ”§ Variables d'environnement

### InjectÃ©es par Render (via render.yaml)

| Service       | Variable     | Valeur injectÃ©e par Render                        |
| ------------- | ------------ | ------------------------------------------------- |
| **API**       | `PORT`       | Automatique (Render)                              |
| **Dashboard** | `PORT`       | Automatique (Render)                              |
| **Dashboard** | `API_URL`    | `https://home-credit-scoring-api.onrender.com`    |
| **Dashboard** | `MLFLOW_URL` | `https://home-credit-scoring-mlflow.onrender.com` |
| **MLflow**    | `PORT`       | Automatique (Render)                              |

> ğŸ’¡ Ces variables sont dÃ©finies dans `render.yaml` et Ã©crasent les valeurs par dÃ©faut des Dockerfiles.

---

## ğŸš€ Ã‰tape 1 : Configuration API sur Render

### 1.1 CrÃ©er un nouveau Web Service

1. Connectez-vous Ã  [dashboard.render.com](https://dashboard.render.com)
2. Cliquez sur **"New +"** â†’ **"Web Service"**
3. SÃ©lectionnez **"Deploy an existing image from a registry"**

### 1.2 Configurer l'image Docker

**Image URL** :

```
ghcr.io/absiinator/openclassrooms-ml-ops-api:latest
```

**ParamÃ¨tres du service** :

- **Name** : `home-credit-api` (ou votre choix)
- **Region** : Europe (Frankfurt) ou proche de vous
- **Instance Type** : **Free** (pour commencer)

### 1.4 Variables d'environnement (optionnel pour l'API)

Ajoutez ces variables si nÃ©cessaire :

```bash
PORT=8000
HOST=0.0.0.0
```

> âš ï¸ **Note** : Sur Render, `PORT` est dÃ©fini automatiquement. Vous n'avez gÃ©nÃ©ralement pas besoin de le configurer manuellement.

## ğŸ¨ Ã‰tape 2 : Configuration Dashboard sur Render

### 2.1 CrÃ©er un nouveau Web Service

RÃ©pÃ©tez les Ã©tapes 1.1 et 1.2 avec ces paramÃ¨tres :

**Image URL** :

```
ghcr.io/absiinator/openclassrooms-ml-ops-dashboard:latest
```

**ParamÃ¨tres du service** :

- **Name** : `home-credit-dashboard`
- **Region** : Europe (Frankfurt)
- **Instance Type** : **Free**

### 2.2 Variables d'environnement Dashboard

**ğŸš¨ OBLIGATOIRE** - Ajoutez ces variables dans Render (onglet "Environment") :

```bash
API_URL=https://home-credit-api.onrender.com
MLFLOW_URL=https://home-credit-mlflow.onrender.com
```

> âš ï¸ **ATTENTION - Configuration Critique** :
>
> 1. **Ces variables DOIVENT Ãªtre configurÃ©es dans Render Web Service â†’ Environment**
> 2. Remplacez `home-credit-api.onrender.com` par l'URL **rÃ©elle** de votre service API Render
> 3. Remplacez `home-credit-mlflow.onrender.com` par l'URL **rÃ©elle** de votre service MLflow Render
> 4. **Format correct** : `https://` + nom-du-service + `.onrender.com`
> 5. **Ne pas utiliser les valeurs par dÃ©faut** `localhost:8000` et `localhost:5000` (ne fonctionnent pas en production)
> 6. **RedÃ©marrer le service Dashboard** aprÃ¨s avoir ajoutÃ© les variables
>
> ğŸ’¡ **Comment trouver vos URLs** :
>
> - API URL : Dashboard Render â†’ service API â†’ copier "Live URL" (ex: `https://home-credit-api.onrender.com`)
> - MLflow URL : Dashboard Render â†’ service MLflow â†’ copier "Live URL" (ex: `https://home-credit-mlflow.onrender.com`)
>
> ğŸ› **Debug** : Dans le Dashboard, cliquez sur "ğŸ” URLs configurÃ©es" dans la sidebar pour vÃ©rifier les URLs actives

## ï¿½ Ã‰tape 2b : Configuration MLflow sur Render

### 2b.1 CrÃ©er un service MLflow

MLflow permet de tracker les expÃ©riences et stocker les modÃ¨les.

1. Cliquez sur **"New +"** â†’ **"Web Service"**
2. SÃ©lectionnez **"Deploy an existing image from a registry"**

**Image URL** :

```
ghcr.io/absiinator/openclassrooms-ml-ops-mlflow:latest
```

â„¹ï¸ Le Dockerfile MLflow (`mlflow/Dockerfile`) est dÃ©jÃ  configurÃ© et l'image sera automatiquement construite par GitHub Actions.

### 2b.2 ParamÃ¨tres du service MLflow

| ParamÃ¨tre              | Valeur                 |
| ----------------------- | ---------------------- |
| **Name**          | `home-scoring-mlflow` |
| **Region**        | Europe (Frankfurt)     |
| **Instance Type** | Free (512MB RAM)       |
| **Port**          | 5000 (ou `$PORT`)    |

âš ï¸ **CRITIQUE - Optimisations pour Free Tier (512MB RAM)** :

Le Dockerfile utilise **`mlflow ui`** (Flask simple) au lieu de **`mlflow server`** (Gunicorn) :

| Configuration | RAM | Status |
|---------------|-----|--------|
| **mlflow ui** (actuel) | ~150-200 MB | âœ… Fonctionne sur 512MB |
| mlflow server --workers 1 | ~250-300 MB | âš ï¸ Instable |
| mlflow server (dÃ©faut) | ~400-500 MB | âŒ CRASH / Out of Memory |

**Avantages de cette approche** :
- âœ… Ã‰conomise 250-350 MB de RAM vs mlflow server
- âœ… Pas de Gunicorn = pas de workers multiples Ã  gÃ©rer
- âœ… Flask intÃ©grÃ© suffisant pour visualiser les runs
- âœ… Le premier dÃ©marrage peut prendre 30-60 secondes (normal)
- âœ… Aucun crash mÃ©moire observÃ©

**Limitations** :
- Les runs sont en lecture seule (pas de nouvelles expÃ©riences persistantes)
- Tier gratuit = service arrÃªtÃ© aprÃ¨s 15 min d'inactivitÃ©

Pour les dÃ©tails techniques, consultez [mlflow/README.md](mlflow/README.md).

ğŸ’¡ **Si MLflow crash avec "Out of Memory"** :

1. VÃ©rifier les logs Render : `Worker was sent SIGKILL! Perhaps out of memory?`
2. **VÃ©rifiez d'abord que le Dockerfile utilise `mlflow ui`** (pas `mlflow server --workers N`)
3. Solutions :
   - âœ… **Upgrade vers un plan payant** (512MB â†’ 2GB RAM) - solution permanente
   - âš ï¸ RedÃ©marrer le service (solution temporaire)
   - ğŸ”„ Alternative : utiliser un stockage S3 au lieu du systÃ¨me de fichiers local

### 2b.3 Variables d'environnement MLflow

Sur Render, aucune variable n'est nÃ©cessaire - `PORT` est dÃ©fini automatiquement.

### 2b.4 Ajouter MLFLOW_URL au Dashboard

**âœ… IMPORTANT** : Retournez au service Dashboard crÃ©Ã© Ã  l'Ã©tape 2 et ajoutez/mettez Ã  jour cette variable d'environnement :

```bash
MLFLOW_URL=https://home-credit-mlflow.onrender.com
```

âš ï¸ Remplacez par l'URL rÃ©elle de votre service MLflow sur Render.

## ğŸ” Ã‰tape 3 : Configuration GitHub

### 3.1 Workflow CI/CD SimplifiÃ©

Le workflow GitHub Actions actuel :

1. **CI** : ExÃ©cute les tests sur chaque push
2. **CD** : Si tests OK â†’ Build les 3 images Docker â†’ Push vers GHCR
3. **DÃ©ploiement** : **MANUEL** sur Render (cliquez "Manual Deploy")

âš ï¸ **Note importante** :

- Le workflow CI/CD **ne nÃ©cessite AUCUN secret** (le dÃ©ploiement est manuel)
- Le seul secret utilisÃ© est `GITHUB_TOKEN` (fourni automatiquement par GitHub)
- Les images Docker sont poussÃ©es vers GHCR (GitHub Container Registry) automatiquement

## âœ… Ã‰tape 4 : DÃ©ploiement et Test

### 4.1 DÃ©ploiement manuel sur Render

**ğŸ”´ Important** : Avec le tier gratuit, le dÃ©ploiement est MANUEL.

**PremiÃ¨re fois** :

1. Retournez dans chaque service sur Render (API, Dashboard, MLflow)
2. Cliquez sur **"Manual Deploy"** â†’ **"Deploy latest commit"**
3. Attendez que le build se termine (â±ï¸ ~5-10 minutes)

**Mises Ã  jour ultÃ©rieures** :

1. Poussez votre code sur `main`
2. Attendez que le workflow GitHub Actions build les nouvelles images (â±ï¸ ~10-15 min)
3. Les images sont automatiquement poussÃ©es vers GHCR
4. **Sur Render, cliquez "Manual Deploy"** pour dÃ©ployer les nouvelles images
5. Render va pull les images depuis GHCR et redÃ©ployer les services

### 4.2 VÃ©rifier que les services fonctionnent

**API** :

```bash
curl https://votre-api.onrender.com/health
```

Devrait retourner :

```json
{
  "status": "healthy",
  "model_loaded": true,
  "version": "1.0.0"
}
```

**Dashboard** :
Ouvrez `https://votre-dashboard.onrender.com` dans votre navigateur.

### 4.3 Workflow de dÃ©ploiement automatisÃ©

1. Faites un commit et push sur `main` :

   ```bash
   git add .
   git commit -m "feat: add new feature"
   git push origin main
   ```
2. VÃ©rifiez dans **Actions** sur GitHub :

   - âœ… CI devrait passer (tests)
   - âœ… CD devrait se dÃ©clencher automatiquement (build images)
   - âœ… Les images Docker devraient Ãªtre publiÃ©es sur GHCR
3. **Sur Render Dashboard** :

   - Ouvrez chaque service (API, Dashboard, MLflow)
   - Cliquez sur **"Manual Deploy"** â†’ **"Clear build cache & deploy"**
   - Attendez le redÃ©ploiement (~5-10 min)

> ğŸ’¡ **Astuce** : Render pull automatiquement la derniÃ¨re image `latest` depuis GHCR lors du manual deploy.

## ğŸ¯ URLs Finales

Une fois dÃ©ployÃ©, notez vos URLs :

```bash
# API
https://home-credit-api.onrender.com

# Dashboard
https://home-credit-dashboard.onrender.com

# MLflow UI
https://home-credit-mlflow.onrender.com

# Documentation API
https://home-credit-api.onrender.com/docs
```

## ğŸ”— RÃ©capitulatif des Variables d'Environnement

### Variables Ã  configurer sur Render

| Service             | Variable       | Valeur                                | Obligatoire ?                    |
| ------------------- | -------------- | ------------------------------------- | -------------------------------- |
| **API**       | `PORT`       | DÃ©fini automatiquement par Render    | âŒ Non                           |
| **API**       | `HOST`       | `0.0.0.0`                           | âŒ Non (dÃ©fini dans Dockerfile) |
| **Dashboard** | `PORT`       | DÃ©fini automatiquement par Render    | âŒ Non                           |
| **Dashboard** | `API_URL`    | `https://votre-api.onrender.com`    | âœ…**OUI**                  |
| **Dashboard** | `MLFLOW_URL` | `https://votre-mlflow.onrender.com` | âœ…**OUI**                  |
| **MLflow**    | `PORT`       | DÃ©fini automatiquement par Render    | âŒ Non                           |

## ğŸ“ Notes Importantes

### âš ï¸ Versions Critiques (Ã  respecter)

| DÃ©pendance | Version | Raison |
|-----------|---------|--------|
| **Pydantic** | >=2.5.0,<3.0.0 | CompatibilitÃ© Optional fields + Pydantic v2 ConfigDict |
| **FastAPI** | >=0.104.0,<0.116.0 | CompatibilitÃ© avec Pydantic v2.5+ |
| **MLflow** | 2.9.2 | LÃ©ger (~50MB) vs versions rÃ©centes (~200MB+) |

âš ï¸ **Si vous updatez ces versions, testez localement d'abord !**

- Les changements Pydantic v3 pourraient casser la validation API (erreur 422)
- Les versions FastAPI incompatibles pourraient casser la sÃ©rialisation JSON
- Les versions MLflow plus rÃ©centes consomment plus de RAM

Consultez [README.md - Versions Critiques](README.md#--versions-critiques---pydantic-v2) pour plus de dÃ©tails.

### âš ï¸ Limitations du Plan Gratuit

- **Sleep aprÃ¨s 15 min d'inactivitÃ©** : Premier appel prend ~30-60s
- **750h/mois** par service gratuit
- **Pas de custom domain** sur le plan gratuit

### ğŸ”„ Workflow de DÃ©ploiement

```mermaid
graph LR
    A[Push sur main] --> B[CI Tests]
    B --> C{Tests OK?}
    C -->|Oui| D[CD: Build Docker Images]
    D --> E[Push vers GHCR]
    E --> F[Images prÃªtes sur GHCR]
    F --> G[Manual Deploy sur Render]
    G --> H[API dÃ©ployÃ©e]
    G --> I[Dashboard dÃ©ployÃ©]
    G --> J[MLflow dÃ©ployÃ©]
    C -->|Non| K[ArrÃªt - Pas de build]
```

**Ã‰tapes** :

1. ğŸ’¾ Push code sur `main`
2. ğŸ§ª CI exÃ©cute les tests
3. âœ… Si tests OK â†’ CD build les 3 images Docker (API, Dashboard, MLflow)
4. ğŸ“¦ Images poussÃ©es vers GHCR (GitHub Container Registry)
5. ğŸ‘¤ **Vous cliquez "Manual Deploy" sur Render** pour chaque service
6. ğŸš€ Render pull les images depuis GHCR et dÃ©ploie

### ğŸ› DÃ©pannage

**ProblÃ¨me : Le dÃ©ploiement Ã©choue**

- VÃ©rifiez les logs dans Render Dashboard
- VÃ©rifiez que les secrets GitHub sont corrects
- VÃ©rifiez que les images sont publiques dans GHCR

**ProblÃ¨me : Dashboard ne peut pas joindre l'API**

- VÃ©rifiez la variable `API_URL` dans le Dashboard
- VÃ©rifiez que l'API est bien dÃ©ployÃ©e et rÃ©pond

**ProblÃ¨me : "Model not loaded"**

- VÃ©rifiez que les modÃ¨les sont bien inclus dans l'image Docker de l'API
- VÃ©rifiez que l'API est dÃ©marrÃ©e et rÃ©pond sur `/health`

**ProblÃ¨me : MLflow - "WORKER TIMEOUT" ou "Out of memory"**

- **Normal au premier dÃ©marrage** - Attendez 1-2 minutes que le service se stabilise
- Le tier gratuit a 512MB RAM - MLflow est configurÃ© avec 1 worker pour Ã©conomiser la mÃ©moire
- Si les erreurs persistent aprÃ¨s 2 minutes, le service devrait fonctionner normalement
- Les workers qui crashent sont automatiquement redÃ©marrÃ©s par Gunicorn

---

## âœ… Checklist Finale

### Ã‰tape 1 : Configuration des Services Render

- [ ] Compte Render crÃ©Ã©
- [ ] **API** : Web Service crÃ©Ã© avec image `ghcr.io/votre-username/openclassrooms-ml-ops-api:latest`
- [ ] **Dashboard** : Web Service crÃ©Ã© avec image `ghcr.io/votre-username/openclassrooms-ml-ops-dashboard:latest`
- [ ] **MLflow** : Web Service crÃ©Ã© avec image `ghcr.io/votre-username/openclassrooms-ml-ops-mlflow:latest`

### Ã‰tape 2 : Variables d'Environnement

- [ ] **Dashboard** : Variable `API_URL` configurÃ©e (ex: `https://votre-api.onrender.com`)
- [ ] **Dashboard** : Variable `MLFLOW_URL` configurÃ©e (ex: `https://votre-mlflow.onrender.com`)
- [ ] Variables vÃ©rifiÃ©es (pas de typo, URLs correctes avec `https://`)

### Ã‰tape 3 : Premier DÃ©ploiement

- [ ] Premier dÃ©ploiement manuel rÃ©ussi pour les 3 services (clic "Manual Deploy")
- [ ] API rÃ©pond sur `/health` avec `"status": "healthy"` et `"model_loaded": true`
- [ ] Dashboard accessible et affiche les statistiques dans la sidebar
- [ ] MLflow UI accessible et affiche les expÃ©riences

### Ã‰tape 4 : Tests Fonctionnels

- [ ] Test prÃ©diction depuis Dashboard : client test â†’ score affichÃ©
- [ ] VÃ©rification sidebar Dashboard : infos modÃ¨le (seuil) et stats dataset visibles
- [ ] MLflow : expÃ©riences "home-credit-scoring" visibles avec runs

### Ã‰tape 5 : Workflow CI/CD

- [ ] Push sur `main` â†’ workflow CI/CD se lance automatiquement
- [ ] Tests passent âœ…
- [ ] Images Docker buildÃ©es et poussÃ©es vers GHCR âœ…
- [ ] "Manual Deploy" effectuÃ© sur Render aprÃ¨s le build
- [ ] Services redÃ©ployÃ©s avec succÃ¨s

**FÃ©licitations ! Votre pipeline CI/CD avec dÃ©ploiement manuel sur Render est opÃ©rationnel ! ğŸ‰**

---

## ğŸ” RÃ©capitulatif des Changements RÃ©cents

### âœ… ModÃ¨les inclus dans l'API

- Les modÃ¨les (`lgbm_model.joblib`, `preprocessor.joblib`, `model_config.json`) sont **inclus dans l'image Docker** de l'API
- L'API les charge automatiquement au dÃ©marrage depuis `/app/models/`
- Le health check `/health` vÃ©rifie que les modÃ¨les sont correctement chargÃ©s

### ğŸ“Š Sidebar du Dashboard enrichie

La barre latÃ©rale contient maintenant **4 sections** :

1. **ğŸ”— Navigation & Services** : Liens vers MLflow et API Docs
2. **ğŸ¥ Ã‰tat des Services** : Statut en temps rÃ©el de l'API et MLflow
3. **ğŸ¤– ModÃ¨le ML** : Seuil optimal et dÃ©tails techniques
4. **ğŸ“Š Statistiques Dataset** (NOUVEAU) :
   - MÃ©triques gÃ©nÃ©rales (nombre clients, variables, taux de dÃ©faut)
   - Statistiques financiÃ¨res (revenu, crÃ©dit)
   - Statistiques dÃ©mographiques (Ã¢ge, genre, enfants)
   - Scores externes (EXT_SOURCE_1, 2, 3)

### ğŸ”„ Workflow CD SimplifiÃ©

- **Avant** : CI/CD avec dÃ©ploiement automatique via API Render (nÃ©cessitait secrets)
- **Maintenant** :
  - CI exÃ©cute les tests
  - CD build les images Docker et les push vers GHCR
  - **DÃ©ploiement MANUEL** sur Render (clic "Manual Deploy")
- **Avantages** : Plus simple, pas de secrets Ã  configurer, compatible avec tier gratuit Render
