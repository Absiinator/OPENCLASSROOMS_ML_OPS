# Guide de Configuration Render pour DÃ©ploiement Automatique

Ce guide vous explique comment configurer Render pour le dÃ©ploiement automatique de votre API et Dashboard.

## ğŸ“‹ PrÃ©requis

1. **Compte Render** : CrÃ©ez un compte gratuit sur [render.com](https://render.com)
2. **Compte GitHub** : Votre repo doit Ãªtre sur GitHub (dÃ©jÃ  fait âœ…)
3. **Images Docker** : Les images seront dans GitHub Container Registry (GHCR)

## ï¿½ Architecture Docker

Le projet utilise 3 Dockerfiles distincts pour les 3 services :

### API (`api/Dockerfile`)
- **Base** : `python:3.10-slim`
- **Port** : 8000
- **Contenu** : 
  - Code source (`src/`, `api/`)
  - âœ… **ModÃ¨les prÃ©-entraÃ®nÃ©s inclus** (`models/lgbm_model.joblib`, `preprocessor.joblib`, `model_config.json`)
  - âœ… **DonnÃ©es tÃ©lÃ©chargÃ©es automatiquement** depuis S3 OpenClassrooms lors du build
  - DÃ©pendances Python pour FastAPI, LightGBM, SHAP
- **TÃ©lÃ©chargement des donnÃ©es** : Le Dockerfile tÃ©lÃ©charge et dÃ©compresse automatiquement les donnÃ©es depuis :
  ```
  https://s3-eu-west-1.amazonaws.com/static.oc-static.com/.../home-credit-default-risk.zip
  ```
- **Variables d'env par dÃ©faut** :
  - `PORT=8000`
  - `PYTHONPATH=/app`
- **Health check** : `/health` (vÃ©rifie que les modÃ¨les sont chargÃ©s)
- **Commande** : `uvicorn api.main:app --host 0.0.0.0 --port $PORT`

### Dashboard (`streamlit_app/Dockerfile`)
- **Base** : `python:3.10-slim`
- **Port** : 8501
- **Contenu** : 
  - App Streamlit (`app.py`) avec 5 onglets (ğŸ¯ Scoring, ğŸ“Š Comparaison, ğŸ“ Import/Simulation, ğŸ“ˆ Drift, ğŸ“– Documentation)
  - Sources (`src/`)
  - âœ… **DonnÃ©es tÃ©lÃ©chargÃ©es automatiquement** depuis S3 OpenClassrooms lors du build
  - **Barre latÃ©rale enrichie** :
    - ğŸ”— Navigation & Services (liens MLflow, API Docs)
    - ğŸ¥ Ã‰tat des services (API, MLflow)
    - ğŸ¤– Informations du modÃ¨le (seuil, version)
    - **ğŸ“Š Statistiques descriptives du dataset** (nombre clients, taux de dÃ©faut, stats financiÃ¨res, dÃ©mographiques, scores externes)
- **TÃ©lÃ©chargement des donnÃ©es** : Le Dockerfile tÃ©lÃ©charge et dÃ©compresse automatiquement les donnÃ©es
- **Variables d'env par dÃ©faut** :
  - `PORT=8501`
  - `API_URL=http://localhost:8000`
  - `MLFLOW_URL=http://localhost:5000`
- **Health check** : `/_stcore/health`
- **Commande** : `streamlit run app.py --server.port=$PORT`

### MLflow (`mlflow/Dockerfile`)
- **Base** : `python:3.10-slim`
- **Port** : 5000
- **Contenu** : RÃ©pertoire `mlruns/` copiÃ© depuis le projet local lors du build
- **Variables d'env par dÃ©faut** :
  - `PORT=5000`
- **Commande** : `mlflow server --host 0.0.0.0 --port $PORT`

âš ï¸ **Notes importantes** : 
- Les **donnÃ©es sont tÃ©lÃ©chargÃ©es automatiquement** lors du build Docker depuis le bucket S3 OpenClassrooms (~500MB)
- Le build Docker prend environ 5-10 minutes supplÃ©mentaires pour le tÃ©lÃ©chargement
- **MLflow** : Les runs du dossier `mlruns/` local sont copiÃ©s dans l'image Docker lors du build GitHub Actions. Ils sont accessibles en lecture seule sur Render. Pour persister de nouvelles expÃ©riences en production, un backend S3 serait nÃ©cessaire (option payante non couverte).

### RÃ©sumÃ© des variables d'environnement par service

| Service | Variable | Valeur par dÃ©faut (Dockerfile) | Configurer sur Render ? |
|---------|----------|-------------------------------|------------------------|
| **API** | `HOST` | 0.0.0.0 | âŒ Non (dÃ©fini dans Dockerfile) |
| **API** | `PORT` | 8000 | âŒ Non (Render le dÃ©finit automatiquement) |
| **Dashboard** | `API_URL` | http://localhost:8000 | âœ… **OUI - OBLIGATOIRE** : `https://votre-api.onrender.com` |
| **Dashboard** | `MLFLOW_URL` | http://localhost:5000 | âœ… **OUI - OBLIGATOIRE** : `https://votre-mlflow.onrender.com` |
| **Dashboard** | `STREAMLIT_SERVER_ADDRESS` | 0.0.0.0 | âŒ Non (dÃ©fini dans Dockerfile) |
| **Dashboard** | `STREAMLIT_SERVER_PORT` | 8501 | âŒ Non (dÃ©fini dans Dockerfile) |
| **Dashboard** | `PORT` | 8501 | âŒ Non (Render le dÃ©finit automatiquement) |
| **MLflow** | `PORT` | 5000 | âŒ Non (Render le dÃ©finit automatiquement) |

> ğŸ’¡ **Important** : Seules `API_URL` et `MLFLOW_URL` du Dashboard nÃ©cessitent une configuration manuelle sur Render.

### Secrets GitHub Actions (dans le repo distant)

| Secret | Description |
|--------|-------------|
| `RENDER_API_KEY` | ClÃ© API Render (non utilisÃ©e actuellement - dÃ©ploiement manuel) |
| `RENDER_SERVICE_API` | ID du service API sur Render |
| `RENDER_SERVICE_DASHBOARD` | ID du service Dashboard sur Render |
| `RENDER_SERVICE_MLFLOW` | ID du service MLflow sur Render |

> âš ï¸ Ces secrets ne sont **pas utilisÃ©s** dans le workflow actuel (dÃ©ploiement manuel). Ils sont prÃ©vus pour un futur dÃ©ploiement automatique.

---

## ï¿½ğŸš€ Ã‰tape 1 : Configuration API sur Render

### 1.1 CrÃ©er un nouveau Web Service

1. Connectez-vous Ã  [dashboard.render.com](https://dashboard.render.com)
2. Cliquez sur **"New +"** â†’ **"Web Service"**
3. SÃ©lectionnez **"Deploy an existing image from a registry"**

### 1.2 Configurer l'image Docker

**Image URL** :
```
ghcr.io/absiinator/openclassrooms-ml-ops-api:latest
```

**ParamÃ¨tres du service** :
- **Name** : `home-credit-api` (ou votre choix)
- **Region** : Europe (Frankfurt) ou proche de vous
- **Instance Type** : **Free** (pour commencer)

### 1.4 Variables d'environnement (optionnel pour l'API)

Ajoutez ces variables si nÃ©cessaire :
```bash
PORT=8000
HOST=0.0.0.0
```

> âš ï¸ **Note** : Sur Render, `PORT` est dÃ©fini automatiquement. Vous n'avez gÃ©nÃ©ralement pas besoin de le configurer manuellement.

## ğŸ¨ Ã‰tape 2 : Configuration Dashboard sur Render

### 2.1 CrÃ©er un nouveau Web Service

RÃ©pÃ©tez les Ã©tapes 1.1 et 1.2 avec ces paramÃ¨tres :

**Image URL** :
```
ghcr.io/absiinator/openclassrooms-ml-ops-dashboard:latest
```

**ParamÃ¨tres du service** :
- **Name** : `home-credit-dashboard`
- **Region** : Europe (Frankfurt)
- **Instance Type** : **Free**

### 2.2 Variables d'environnement Dashboard

**ğŸš¨ OBLIGATOIRE** - Ajoutez ces variables dans Render (onglet "Environment") :
```bash
API_URL=https://home-credit-api.onrender.com
MLFLOW_URL=https://home-credit-mlflow.onrender.com
```

> âš ï¸ **ATTENTION - Configuration Critique** : 
> 1. **Ces variables DOIVENT Ãªtre configurÃ©es dans Render Web Service â†’ Environment**
> 2. Remplacez `home-credit-api.onrender.com` par l'URL **rÃ©elle** de votre service API Render
> 3. Remplacez `home-credit-mlflow.onrender.com` par l'URL **rÃ©elle** de votre service MLflow Render
> 4. **Format correct** : `https://` + nom-du-service + `.onrender.com`
> 5. **Ne pas utiliser les valeurs par dÃ©faut** `localhost:8000` et `localhost:5000` (ne fonctionnent pas en production)
> 6. **RedÃ©marrer le service Dashboard** aprÃ¨s avoir ajoutÃ© les variables
> 
> ğŸ’¡ **Comment trouver vos URLs** :
> - API URL : Dashboard Render â†’ service API â†’ copier "Live URL" (ex: `https://home-credit-api.onrender.com`)
> - MLflow URL : Dashboard Render â†’ service MLflow â†’ copier "Live URL" (ex: `https://home-credit-mlflow.onrender.com`)
> 
> ğŸ› **Debug** : Dans le Dashboard, cliquez sur "ğŸ” URLs configurÃ©es" dans la sidebar pour vÃ©rifier les URLs actives

## ï¿½ Ã‰tape 2b : Configuration MLflow sur Render

### 2b.1 CrÃ©er un service MLflow

MLflow permet de tracker les expÃ©riences et stocker les modÃ¨les.

1. Cliquez sur **"New +"** â†’ **"Web Service"**
2. SÃ©lectionnez **"Deploy an existing image from a registry"**

**Image URL** :

```
ghcr.io/absiinator/openclassrooms-ml-ops-mlflow:latest
```

â„¹ï¸ Le Dockerfile MLflow (`mlflow/Dockerfile`) est dÃ©jÃ  configurÃ© et l'image sera automatiquement construite par GitHub Actions.

### 2b.2 ParamÃ¨tres du service MLflow

| ParamÃ¨tre | Valeur |
|-----------|--------|
| **Name** | `home-credit-mlflow` |
| **Region** | Europe (Frankfurt) |
| **Instance Type** | Free (512MB RAM) |
| **Port** | 5000 (ou `$PORT`) |

âš ï¸ **Important - Optimisations pour Free Tier** :
- Le Dockerfile utilise **`mlflow ui`** au lieu de `mlflow server` (pas de gunicorn = moins de RAM)
- `mlflow ui` utilise Flask intÃ©grÃ© - **parfait pour 512MB RAM du tier gratuit**
- Les chemins `artifact_location` et `artifact_uri` sont automatiquement corrigÃ©s pour Docker
- DÃ©pendances minimales pour Ã©conomiser la RAM
- Le premier dÃ©marrage peut prendre 30-60 secondes

ğŸ’¡ **Si MLflow crash avec "Out of Memory"** :
1. VÃ©rifier les logs Render : `Worker was sent SIGKILL! Perhaps out of memory?`
2. Solutions : 
   - âœ… Upgrade vers un plan payant (512MB â†’ 2GB RAM)
   - âš ï¸ RedÃ©marrer le service (solution temporaire)
   - ğŸ”„ Alternative : utiliser un stockage S3 au lieu du systÃ¨me de fichiers local

### 2b.3 Variables d'environnement MLflow

Sur Render, aucune variable n'est nÃ©cessaire - `PORT` est dÃ©fini automatiquement.

### 2b.4 Ajouter MLFLOW_URL au Dashboard

**âœ… IMPORTANT** : Retournez au service Dashboard crÃ©Ã© Ã  l'Ã©tape 2 et ajoutez/mettez Ã  jour cette variable d'environnement :

```bash
MLFLOW_URL=https://home-credit-mlflow.onrender.com
```

âš ï¸ Remplacez par l'URL rÃ©elle de votre service MLflow sur Render.

## ğŸ” Ã‰tape 3 : Configuration GitHub

### 3.1 Workflow CI/CD SimplifiÃ©

Le workflow GitHub Actions actuel :
1. **CI** : ExÃ©cute les tests sur chaque push
2. **CD** : Si tests OK â†’ Build les 3 images Docker â†’ Push vers GHCR
3. **DÃ©ploiement** : **MANUEL** sur Render (cliquez "Manual Deploy")

âš ï¸ **Note importante** :
- Le workflow CI/CD **ne nÃ©cessite AUCUN secret** (le dÃ©ploiement est manuel)
- Le seul secret utilisÃ© est `GITHUB_TOKEN` (fourni automatiquement par GitHub)
- Les images Docker sont poussÃ©es vers GHCR (GitHub Container Registry) automatiquement

### 3.2 Variables GitHub (Optionnelles)

Si vous souhaitez rÃ©fÃ©rencer vos URLs dans des workflows futurs, ajoutez ces **variables** (pas des secrets) :

1. Allez sur votre repo GitHub
2. **Settings** â†’ **Secrets and variables** â†’ **Actions**
3. Cliquez sur l'onglet **"Variables"**
4. Cliquez sur **"New repository variable"**

**Variables optionnelles** :

| Nom | Valeur | Description |
|-----|--------|-------------|
| `RENDER_API_URL` | `https://votre-api.onrender.com` | URL de l'API dÃ©ployÃ©e |
| `RENDER_DASHBOARD_URL` | `https://votre-dashboard.onrender.com` | URL du Dashboard dÃ©ployÃ© |
| `RENDER_MLFLOW_URL` | `https://votre-mlflow.onrender.com` | URL de MLflow dÃ©ployÃ© |

> ğŸ’¡ **Ces variables ne sont PAS nÃ©cessaires** pour le dÃ©ploiement manuel actuel. Elles sont utiles uniquement si vous ajoutez des tests d'intÃ©gration ou des notifications post-dÃ©ploiement.

## âœ… Ã‰tape 4 : DÃ©ploiement et Test

### 4.1 DÃ©ploiement manuel sur Render

**ğŸ”´ Important** : Avec le tier gratuit, le dÃ©ploiement est MANUEL.

**PremiÃ¨re fois** :
1. Retournez dans chaque service sur Render (API, Dashboard, MLflow)
2. Cliquez sur **"Manual Deploy"** â†’ **"Deploy latest commit"**
3. Attendez que le build se termine (â±ï¸ ~5-10 minutes)

**Mises Ã  jour ultÃ©rieures** :
1. Poussez votre code sur `main`
2. Attendez que le workflow GitHub Actions build les nouvelles images (â±ï¸ ~10-15 min)
3. Les images sont automatiquement poussÃ©es vers GHCR
4. **Sur Render, cliquez "Manual Deploy"** pour dÃ©ployer les nouvelles images
5. Render va pull les images depuis GHCR et redÃ©ployer les services

### 4.2 VÃ©rifier que les services fonctionnent

**API** :
```bash
curl https://votre-api.onrender.com/health
```

Devrait retourner :
```json
{
  "status": "healthy",
  "model_loaded": true,
  "version": "1.0.0"
}
```

**Dashboard** :
Ouvrez `https://votre-dashboard.onrender.com` dans votre navigateur.

### 4.3 Workflow de dÃ©ploiement automatisÃ©

1. Faites un commit et push sur `main` :
   ```bash
   git add .
   git commit -m "feat: add new feature"
   git push origin main
   ```

2. VÃ©rifiez dans **Actions** sur GitHub :
   - âœ… CI devrait passer (tests)
   - âœ… CD devrait se dÃ©clencher automatiquement (build images)
   - âœ… Les images Docker devraient Ãªtre publiÃ©es sur GHCR

3. **Sur Render Dashboard** :
   - Ouvrez chaque service (API, Dashboard, MLflow)
   - Cliquez sur **"Manual Deploy"** â†’ **"Clear build cache & deploy"**
   - Attendez le redÃ©ploiement (~5-10 min)

> ğŸ’¡ **Astuce** : Render pull automatiquement la derniÃ¨re image `latest` depuis GHCR lors du manual deploy.

## ğŸ¯ URLs Finales

Une fois dÃ©ployÃ©, notez vos URLs :

```bash
# API
https://home-credit-api.onrender.com

# Dashboard
https://home-credit-dashboard.onrender.com

# MLflow UI
https://home-credit-mlflow.onrender.com

# Documentation API
https://home-credit-api.onrender.com/docs
```

## ğŸ”— RÃ©capitulatif des Variables d'Environnement

### Variables Ã  configurer sur Render

| Service | Variable | Valeur | Obligatoire ? |
|---------|----------|--------|---------------|
| **API** | `PORT` | DÃ©fini automatiquement par Render | âŒ Non |
| **API** | `HOST` | `0.0.0.0` | âŒ Non (dÃ©fini dans Dockerfile) |
| **Dashboard** | `PORT` | DÃ©fini automatiquement par Render | âŒ Non |
| **Dashboard** | `API_URL` | `https://votre-api.onrender.com` | âœ… **OUI** |
| **Dashboard** | `MLFLOW_URL` | `https://votre-mlflow.onrender.com` | âœ… **OUI** |
| **MLflow** | `PORT` | DÃ©fini automatiquement par Render | âŒ Non |

### Variables GitHub (Optionnelles)

Ces variables ne sont **pas nÃ©cessaires** pour le dÃ©ploiement actuel (dÃ©ploiement manuel).

| Nom | Valeur | Usage |
|-----|--------|-------|
| `RENDER_API_URL` | `https://votre-api.onrender.com` | Tests d'intÃ©gration (futurs) |
| `RENDER_DASHBOARD_URL` | `https://votre-dashboard.onrender.com` | Tests d'intÃ©gration (futurs) |
| `RENDER_MLFLOW_URL` | `https://votre-mlflow.onrender.com` | Tests d'intÃ©gration (futurs) |

## ğŸ“ Notes Importantes

### âš ï¸ Limitations du Plan Gratuit

- **Sleep aprÃ¨s 15 min d'inactivitÃ©** : Premier appel prend ~30-60s
- **750h/mois** par service gratuit
- **Pas de custom domain** sur le plan gratuit

### ğŸ”„ Workflow de DÃ©ploiement

```mermaid
graph LR
    A[Push sur main] --> B[CI Tests]
    B --> C{Tests OK?}
    C -->|Oui| D[CD: Build Docker Images]
    D --> E[Push vers GHCR]
    E --> F[Images prÃªtes sur GHCR]
    F --> G[Manual Deploy sur Render]
    G --> H[API dÃ©ployÃ©e]
    G --> I[Dashboard dÃ©ployÃ©]
    G --> J[MLflow dÃ©ployÃ©]
    C -->|Non| K[ArrÃªt - Pas de build]
```

**Ã‰tapes** :
1. ğŸ’¾ Push code sur `main`
2. ğŸ§ª CI exÃ©cute les tests
3. âœ… Si tests OK â†’ CD build les 3 images Docker (API, Dashboard, MLflow)
4. ğŸ“¦ Images poussÃ©es vers GHCR (GitHub Container Registry)
5. ğŸ‘¤ **Vous cliquez "Manual Deploy" sur Render** pour chaque service
6. ğŸš€ Render pull les images depuis GHCR et dÃ©ploie

### ğŸ› DÃ©pannage

**ProblÃ¨me : Le dÃ©ploiement Ã©choue**
- VÃ©rifiez les logs dans Render Dashboard
- VÃ©rifiez que les secrets GitHub sont corrects
- VÃ©rifiez que les images sont publiques dans GHCR

**ProblÃ¨me : Dashboard ne peut pas joindre l'API**
- VÃ©rifiez la variable `API_URL` dans le Dashboard
- VÃ©rifiez que l'API est bien dÃ©ployÃ©e et rÃ©pond

**ProblÃ¨me : "Model not loaded"**
- VÃ©rifiez que les modÃ¨les sont bien inclus dans l'image Docker de l'API
- VÃ©rifiez que l'API est dÃ©marrÃ©e et rÃ©pond sur `/health`

**ProblÃ¨me : MLflow - "WORKER TIMEOUT" ou "Out of memory"**
- **Normal au premier dÃ©marrage** - Attendez 1-2 minutes que le service se stabilise
- Le tier gratuit a 512MB RAM - MLflow est configurÃ© avec 1 worker pour Ã©conomiser la mÃ©moire
- Si les erreurs persistent aprÃ¨s 2 minutes, le service devrait fonctionner normalement
- Les workers qui crashent sont automatiquement redÃ©marrÃ©s par Gunicorn

---

## âœ… Checklist Finale

### Ã‰tape 1 : Configuration des Services Render
- [ ] Compte Render crÃ©Ã©
- [ ] **API** : Web Service crÃ©Ã© avec image `ghcr.io/votre-username/openclassrooms-ml-ops-api:latest`
- [ ] **Dashboard** : Web Service crÃ©Ã© avec image `ghcr.io/votre-username/openclassrooms-ml-ops-dashboard:latest`
- [ ] **MLflow** : Web Service crÃ©Ã© avec image `ghcr.io/votre-username/openclassrooms-ml-ops-mlflow:latest`

### Ã‰tape 2 : Variables d'Environnement
- [ ] **Dashboard** : Variable `API_URL` configurÃ©e (ex: `https://votre-api.onrender.com`)
- [ ] **Dashboard** : Variable `MLFLOW_URL` configurÃ©e (ex: `https://votre-mlflow.onrender.com`)
- [ ] Variables vÃ©rifiÃ©es (pas de typo, URLs correctes avec `https://`)

### Ã‰tape 3 : Premier DÃ©ploiement
- [ ] Premier dÃ©ploiement manuel rÃ©ussi pour les 3 services (clic "Manual Deploy")
- [ ] API rÃ©pond sur `/health` avec `"status": "healthy"` et `"model_loaded": true`
- [ ] Dashboard accessible et affiche les statistiques dans la sidebar
- [ ] MLflow UI accessible et affiche les expÃ©riences

### Ã‰tape 4 : Tests Fonctionnels
- [ ] Test prÃ©diction depuis Dashboard : client test â†’ score affichÃ©
- [ ] VÃ©rification sidebar Dashboard : infos modÃ¨le (seuil) et stats dataset visibles
- [ ] MLflow : expÃ©riences "home-credit-scoring" visibles avec runs

### Ã‰tape 5 : Workflow CI/CD
- [ ] Push sur `main` â†’ workflow CI/CD se lance automatiquement
- [ ] Tests passent âœ…
- [ ] Images Docker buildÃ©es et poussÃ©es vers GHCR âœ…
- [ ] "Manual Deploy" effectuÃ© sur Render aprÃ¨s le build
- [ ] Services redÃ©ployÃ©s avec succÃ¨s

**FÃ©licitations ! Votre pipeline CI/CD avec dÃ©ploiement manuel sur Render est opÃ©rationnel ! ğŸ‰**

---

## ğŸ” RÃ©capitulatif des Changements RÃ©cents

### âœ… ModÃ¨les inclus dans l'API
- Les modÃ¨les (`lgbm_model.joblib`, `preprocessor.joblib`, `model_config.json`) sont **inclus dans l'image Docker** de l'API
- L'API les charge automatiquement au dÃ©marrage depuis `/app/models/`
- Le health check `/health` vÃ©rifie que les modÃ¨les sont correctement chargÃ©s

### ğŸ“Š Sidebar du Dashboard enrichie
La barre latÃ©rale contient maintenant **4 sections** :
1. **ğŸ”— Navigation & Services** : Liens vers MLflow et API Docs
2. **ğŸ¥ Ã‰tat des Services** : Statut en temps rÃ©el de l'API et MLflow
3. **ğŸ¤– ModÃ¨le ML** : Seuil optimal et dÃ©tails techniques
4. **ğŸ“Š Statistiques Dataset** (NOUVEAU) :
   - MÃ©triques gÃ©nÃ©rales (nombre clients, variables, taux de dÃ©faut)
   - Statistiques financiÃ¨res (revenu, crÃ©dit)
   - Statistiques dÃ©mographiques (Ã¢ge, genre, enfants)
   - Scores externes (EXT_SOURCE_1, 2, 3)

### ğŸ”„ Workflow CD SimplifiÃ©
- **Avant** : CI/CD avec dÃ©ploiement automatique via API Render (nÃ©cessitait secrets)
- **Maintenant** : 
  - CI exÃ©cute les tests
  - CD build les images Docker et les push vers GHCR
  - **DÃ©ploiement MANUEL** sur Render (clic "Manual Deploy")
- **Avantages** : Plus simple, pas de secrets Ã  configurer, compatible avec tier gratuit Render
