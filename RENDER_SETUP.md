# Guide de Configuration Render pour DÃ©ploiement Automatique

Ce guide vous explique comment configurer Render pour le dÃ©ploiement automatique de votre API et Dashboard.

## ğŸ“‹ PrÃ©requis

1. **Compte Render** : CrÃ©ez un compte gratuit sur [render.com](https://render.com)
2. **Compte GitHub** : Votre repo doit Ãªtre sur GitHub (dÃ©jÃ  fait âœ…)
3. **Images Docker** : Les images seront dans GitHub Container Registry (GHCR)

## ï¿½ Architecture Docker

Le projet utilise 3 Dockerfiles distincts pour les 3 services :

### API (`api/Dockerfile`)
- **Base** : `python:3.10-slim`
- **Port** : 8000
- **Contenu** : 
  - Code source (`src/`, `api/`)
  - âœ… **ModÃ¨les prÃ©-entraÃ®nÃ©s inclus** (`models/lgbm_model.joblib`, `preprocessor.joblib`, `model_config.json`)
  - âœ… **DonnÃ©es tÃ©lÃ©chargÃ©es automatiquement** depuis S3 OpenClassrooms lors du build
  - DÃ©pendances Python pour FastAPI, LightGBM, SHAP
- **TÃ©lÃ©chargement des donnÃ©es** : Le Dockerfile tÃ©lÃ©charge et dÃ©compresse automatiquement les donnÃ©es depuis :
  ```
  https://s3-eu-west-1.amazonaws.com/static.oc-static.com/.../home-credit-default-risk.zip
  ```
- **Variables d'env par dÃ©faut** :
  - `PORT=8000`
  - `PYTHONPATH=/app`
- **Health check** : `/health` (vÃ©rifie que les modÃ¨les sont chargÃ©s)
- **Commande** : `uvicorn api.main:app --host 0.0.0.0 --port $PORT`

### Dashboard (`streamlit_app/Dockerfile`)
- **Base** : `python:3.10-slim`
- **Port** : 8501
- **Contenu** : 
  - App Streamlit (`app.py`) avec 5 onglets (ğŸ¯ Scoring, ğŸ“Š Comparaison, ğŸ“ Import/Simulation, ğŸ“ˆ Drift, ğŸ“– Documentation)
  - Sources (`src/`)
  - ModÃ¨les (fallback local si API indisponible)
  - âœ… **DonnÃ©es tÃ©lÃ©chargÃ©es automatiquement** depuis S3 OpenClassrooms lors du build
  - **Barre latÃ©rale enrichie** :
    - ğŸ”— Navigation & Services (liens MLflow, API Docs)
    - ğŸ¥ Ã‰tat des services (API, MLflow)
    - ğŸ¤– Informations du modÃ¨le (seuil, version)
    - **ğŸ“Š Statistiques descriptives du dataset** (nombre clients, taux de dÃ©faut, stats financiÃ¨res, dÃ©mographiques, scores externes)
- **TÃ©lÃ©chargement des donnÃ©es** : Le Dockerfile tÃ©lÃ©charge et dÃ©compresse automatiquement les donnÃ©es
- **Variables d'env par dÃ©faut** :
  - `PORT=8501`
  - `API_URL=http://localhost:8000`
  - `MLFLOW_URL=http://localhost:5002`
- **Health check** : `/_stcore/health`
- **Commande** : `streamlit run app.py --server.port=$PORT`

### MLflow (`mlflow/Dockerfile`)
- **Base** : `python:3.10-slim`
- **Port** : 5000
- **Contenu** : RÃ©pertoire `mlruns/` copiÃ© depuis le projet local lors du build
- **Variables d'env par dÃ©faut** :
  - `PORT=5000`
- **Commande** : `mlflow server --host 0.0.0.0 --port $PORT`

âš ï¸ **Notes importantes** : 
- Les **donnÃ©es sont tÃ©lÃ©chargÃ©es automatiquement** lors du build Docker depuis le bucket S3 OpenClassrooms (~500MB)
- Le build Docker prend environ 5-10 minutes supplÃ©mentaires pour le tÃ©lÃ©chargement
- **MLflow** : Les runs du dossier `mlruns/` local sont copiÃ©s dans l'image Docker lors du build GitHub Actions. Ils sont accessibles en lecture seule sur Render. Pour persister de nouvelles expÃ©riences en production, un backend S3 serait nÃ©cessaire (option payante non couverte).
### RÃ©sumÃ© des variables d'environnement par service

| Service | Variable | Valeur par dÃ©faut | Ã€ configurer sur Render |
|---------|----------|-------------------|-------------------------|
| **API** | `PORT` | 8000 | Automatique (Render) |
| **API** | `HOST` | 0.0.0.0 | âœ… Optionnel |
| **Dashboard** | `PORT` | 8501 | Automatique (Render) |
| **Dashboard** | `API_URL` | http://localhost:8000 | âœ… **Obligatoire** : `https://votre-api.onrender.com` |
| **Dashboard** | `MLFLOW_URL` | http://localhost:5002 | âœ… **Obligatoire** : `https://votre-mlflow.onrender.com` |
| **MLflow** | `PORT` | 5000 | Automatique (Render) |
---

## ï¿½ğŸš€ Ã‰tape 1 : Configuration API sur Render

### 1.1 CrÃ©er un nouveau Web Service

1. Connectez-vous Ã  [dashboard.render.com](https://dashboard.render.com)
2. Cliquez sur **"New +"** â†’ **"Web Service"**
3. SÃ©lectionnez **"Deploy an existing image from a registry"**

### 1.2 Configurer l'image Docker

**Image URL** :
```
ghcr.io/absiinator/openclassrooms-ml-ops-api:latest
```

**ParamÃ¨tres du service** :
- **Name** : `home-credit-api` (ou votre choix)
- **Region** : Europe (Frankfurt) ou proche de vous
- **Instance Type** : **Free** (pour commencer)

### 1.3 Variables d'environnement (optionnel pour l'API)

Ajoutez ces variables si nÃ©cessaire :
```bash
PORT=8000
HOST=0.0.0.0
```

### 1.4 RÃ©cupÃ©rer l'API Key pour le dÃ©ploiement automatique

1. Allez dans **Account Settings** (icÃ´ne utilisateur en haut Ã  droite)
2. Cliquez sur **"API Keys"** dans le menu gauche
3. Cliquez sur **"Create API Key"**
4. Donnez un nom : `GitHub Actions Deploy`
5. **COPIEZ LA CLÃ‰** (vous ne la reverrez plus !)

### 1.5 RÃ©cupÃ©rer le Service ID

1. Ouvrez votre service API crÃ©Ã©
2. Dans l'URL, copiez l'ID (exemple : `srv-xxxxxxxxxxxxx`)
   ```
   https://dashboard.render.com/web/srv-xxxxxxxxxxxxx
                                      ^^^^^^^^^^^^^^^^
   ```

## ğŸ¨ Ã‰tape 2 : Configuration Dashboard sur Render

### 2.1 CrÃ©er un nouveau Web Service

RÃ©pÃ©tez les Ã©tapes 1.1 Ã  1.3 avec ces paramÃ¨tres :

**Image URL** :
```
ghcr.io/absiinator/openclassrooms-ml-ops-dashboard:latest
```

**ParamÃ¨tres du service** :
- **Name** : `home-credit-dashboard`
- **Region** : Europe (Frankfurt)
- **Instance Type** : **Free**

### 2.2 Variables d'environnement Dashboard

**Obligatoire** - Ajoutez ces variables :
```bash
API_URL=https://home-credit-api.onrender.com
MLFLOW_URL=https://home-credit-mlflow.onrender.com
```

**Optionnel** - Configuration Streamlit (dÃ©jÃ  dÃ©finies dans le Dockerfile) :
```bash
STREAMLIT_SERVER_PORT=8501
STREAMLIT_SERVER_ADDRESS=0.0.0.0
```

âš ï¸ **Important** : 
- Remplacez `home-credit-api.onrender.com` par l'URL rÃ©elle de votre API
- Vous ajouterez `MLFLOW_URL` aprÃ¨s avoir crÃ©Ã© le service MLflow (Ã©tape 2b)

### 2.3 RÃ©cupÃ©rer le Service ID Dashboard

MÃªme procÃ©dure que 1.5, copiez le Service ID du Dashboard.

## ï¿½ Ã‰tape 2b : Configuration MLflow sur Render

### 2b.1 CrÃ©er un service MLflow

MLflow permet de tracker les expÃ©riences et stocker les modÃ¨les.

1. Cliquez sur **"New +"** â†’ **"Web Service"**
2. SÃ©lectionnez **"Deploy an existing image from a registry"**

**Image URL** :

```
ghcr.io/absiinator/openclassrooms-ml-ops-mlflow:latest
```

â„¹ï¸ Le Dockerfile MLflow (`mlflow/Dockerfile`) est dÃ©jÃ  configurÃ© et l'image sera automatiquement construite par GitHub Actions.

### 2b.2 ParamÃ¨tres du service MLflow

| ParamÃ¨tre | Valeur |
|-----------|--------|
| **Name** | `home-credit-mlflow` |
| **Region** | Europe (Frankfurt) |
| **Instance Type** | Free (512MB RAM) |
| **Port** | 5000 (ou `$PORT`) |

âš ï¸ **Important - Optimisations appliquÃ©es** :
- Le Dockerfile est configurÃ© avec **1 worker** au lieu de 4 par dÃ©faut
- Timeout augmentÃ© Ã  **120 secondes** pour Ã©viter les crashs
- DÃ©pendances minimales (pas de boto3/psycopg2) pour Ã©conomiser la RAM
- Si vous voyez des erreurs "WORKER TIMEOUT" au dÃ©marrage, c'est normal - attendez 1-2 minutes que le service se stabilise

### 2b.3 RÃ©cupÃ©rer le Service ID MLflow

MÃªme procÃ©dure que pour l'API et le Dashboard.

### 2b.4 Ajouter MLFLOW_URL au Dashboard

**Important** : Retournez au service Dashboard crÃ©Ã© Ã  l'Ã©tape 2 et ajoutez cette variable d'environnement :

```bash
MLFLOW_URL=https://home-credit-mlflow.onrender.com
```

âš ï¸ Remplacez par l'URL rÃ©elle de votre service MLflow sur Render.

## ğŸ” Ã‰tape 3 : Configuration GitHub (Optionnel)

### 3.1 Workflow CI/CD SimplifiÃ©

Le workflow GitHub Actions actuel :
1. **CI** : ExÃ©cute les tests sur chaque push
2. **CD** : Si tests OK â†’ Build les 3 images Docker â†’ Push vers GHCR
3. **DÃ©ploiement** : **MANUEL** sur Render (cliquez "Manual Deploy")

âš ï¸ **Note importante** :
- **En local** (avec `python run.py ...`), aucune variable secrÃ¨te n'est requise.
- **Sur Render ou tout environnement distant**, les secrets GitHub sont **OBLIGATOIRES** pour que le dÃ©ploiement fonctionne correctement (API, Dashboard, MLflow).

### 3.2 Secrets GitHub (**Obligatoires pour Render**)

Pour tout dÃ©ploiement sur Render (ou tout environnement non local), ajoutez ces secrets dans GitHub :

1. Allez sur votre repo GitHub
2. **Settings** â†’ **Secrets and variables** â†’ **Actions**
3. Cliquez sur **"New repository secret"**

**Secrets Ã  ajouter (OBLIGATOIRES pour Render)** :

| Nom | Valeur | Description | NÃ©cessaire ? |
|-----|--------|-------------|-------------|
| `RENDER_API_KEY` | Votre clÃ© API Render | ClÃ© copiÃ©e Ã  l'Ã©tape 1.4 | âœ… Oui (dÃ©ploiement Render) |
| `RENDER_SERVICE_API` | `srv-xxxxxxxxxxxxx` | Service ID de l'API (Ã©tape 1.5) | âœ… Oui (dÃ©ploiement Render) |
| `RENDER_SERVICE_DASHBOARD` | `srv-xxxxxxxxxxxxx` | Service ID du Dashboard (Ã©tape 2.3) | âœ… Oui (dÃ©ploiement Render) |
| `RENDER_SERVICE_MLFLOW` | `srv-xxxxxxxxxxxxx` | Service ID de MLflow (Ã©tape 2b.3) | âœ… Oui (dÃ©ploiement Render) |

> ğŸ’¡ **Astuce** : Les secrets sont uniquement optionnels si vous testez tout en local avec `run.py`. Pour tout dÃ©ploiement sur Render, ils sont impÃ©ratifs.

## âœ… Ã‰tape 4 : DÃ©ploiement et Test

### 4.1 DÃ©ploiement manuel sur Render

**ğŸ”´ Important** : Avec le tier gratuit, le dÃ©ploiement est MANUEL.

**PremiÃ¨re fois** :
1. Retournez dans chaque service sur Render (API, Dashboard, MLflow)
2. Cliquez sur **"Manual Deploy"** â†’ **"Deploy latest commit"**
3. Attendez que le build se termine (â±ï¸ ~5-10 minutes)

**Mises Ã  jour ultÃ©rieures** :
1. Poussez votre code sur `main`
2. Attendez que le workflow GitHub Actions build les nouvelles images (â±ï¸ ~10-15 min)
3. Les images sont automatiquement poussÃ©es vers GHCR
4. **Sur Render, cliquez "Manual Deploy"** pour dÃ©ployer les nouvelles images
5. Render va pull les images depuis GHCR et redÃ©ployer les services

### 4.2 VÃ©rifier que les services fonctionnent

**API** :
```bash
curl https://votre-api.onrender.com/health
```

Devrait retourner :
```json
{
  "status": "healthy",
  "model_loaded": true,
  "version": "1.0.0"
}
```

**Dashboard** :
Ouvrez `https://votre-dashboard.onrender.com` dans votre navigateur.

### 4.3 Workflow de dÃ©ploiement automatisÃ©

1. Faites un commit et push sur `main` :
   ```bash
   git add .
   git commit -m "feat: add new feature"
   git push origin main
   ```

2. VÃ©rifiez dans **Actions** sur GitHub :
   - âœ… CI devrait passer (tests)
   - âœ… CD devrait se dÃ©clencher automatiquement (build images)
   - âœ… Les images Docker devraient Ãªtre publiÃ©es sur GHCR

3. **Sur Render Dashboard** :
   - Ouvrez chaque service (API, Dashboard, MLflow)
   - Cliquez sur **"Manual Deploy"** â†’ **"Clear build cache & deploy"**
   - Attendez le redÃ©ploiement (~5-10 min)

> ğŸ’¡ **Astuce** : Render pull automatiquement la derniÃ¨re image `latest` depuis GHCR lors du manual deploy.

## ğŸ¯ URLs Finales

Une fois dÃ©ployÃ©, notez vos URLs :

```bash
# API
https://home-credit-api.onrender.com

# Dashboard
https://home-credit-dashboard.onrender.com

# MLflow UI
https://home-credit-mlflow.onrender.com

# Documentation API
https://home-credit-api.onrender.com/docs
```

## ğŸ”— Variables d'environnement GitHub

Pour que les URLs soient disponibles comme variables d'environnement dans les workflows CI/CD, ajoutez-les comme **variables** (pas secrets) dans GitHub :

1. Allez dans **Settings** â†’ **Secrets and variables** â†’ **Actions**
2. Cliquez sur l'onglet **"Variables"**
3. Ajoutez les variables suivantes :

| Nom | Valeur |
|-----|--------|
| `RENDER_API_URL` | `https://home-credit-api.onrender.com` |
| `RENDER_DASHBOARD_URL` | `https://home-credit-dashboard.onrender.com` |
| `RENDER_MLFLOW_URL` | `https://home-credit-mlflow.onrender.com` |

Ces variables peuvent ensuite Ãªtre utilisÃ©es dans les workflows avec `${{ vars.RENDER_API_URL }}`.

## ğŸ“ Notes Importantes

### âš ï¸ Limitations du Plan Gratuit

- **Sleep aprÃ¨s 15 min d'inactivitÃ©** : Premier appel prend ~30-60s
- **750h/mois** par service gratuit
- **Pas de custom domain** sur le plan gratuit

### ğŸ”„ Workflow de DÃ©ploiement

```mermaid
graph LR
    A[Push sur main] --> B[CI Tests]
    B --> C{Tests OK?}
    C -->|ğŸš€ Oui| D[CD: Build Docker Images]
    D --> E[Push vers GHCR]
    E --> F[Images prÃªtes sur GHCR]
    F --> G[Manual Deploy sur Render]
    G --> H[API dÃ©ployÃ©e]
    G --> I[Dashboard dÃ©ployÃ©]
    G --> J[MLflow dÃ©ployÃ©]
    C -->|âŒ Non| K[ArrÃªt - Pas de build]
```

**Ã‰tapes** :
1. ğŸ’¾ Push code sur `main`
2. ğŸ§ª CI exÃ©cute les tests
3. âœ… Si tests OK â†’ CD build les 3 images Docker (API, Dashboard, MLflow)
4. ğŸ“¦ Images poussÃ©es vers GHCR (GitHub Container Registry)
5. ğŸ‘¤ **Vous cliquez "Manual Deploy" sur Render** pour chaque service
6. ğŸš€ Render pull les images depuis GHCR et dÃ©ploie

### ğŸ› DÃ©pannage

**ProblÃ¨me : Le dÃ©ploiement Ã©choue**
- VÃ©rifiez les logs dans Render Dashboard
- VÃ©rifiez que les secrets GitHub sont corrects
- VÃ©rifiez que les images sont publiques dans GHCR

**ProblÃ¨me : Dashboard ne peut pas joindre l'API**
- VÃ©rifiez la variable `API_URL` dans le Dashboard
- VÃ©rifiez que l'API est bien dÃ©ployÃ©e et rÃ©pond

**ProblÃ¨me : "Model not loaded"**
- Normal si les modÃ¨les ne sont pas inclus dans l'image Docker
- Le Dashboard utilise automatiquement le fallback local si l'API ne rÃ©pond pas

**ProblÃ¨me : MLflow - "WORKER TIMEOUT" ou "Out of memory"**
- **Normal au premier dÃ©marrage** - Attendez 1-2 minutes que le service se stabilise
- Le tier gratuit a 512MB RAM - MLflow est configurÃ© avec 1 worker pour Ã©conomiser la mÃ©moire
- Si les erreurs persistent aprÃ¨s 2 minutes, le service devrait fonctionner normalement
- Les workers qui crashent sont automatiquement redÃ©marrÃ©s par Gunicorn

---

## âœ… Checklist Finale

- [ ] Compte Render crÃ©Ã©
- [ ] Web Service API crÃ©Ã© (Image: `ghcr.io/username/openclassrooms-ml-ops-api:latest`)
- [ ] Web Service Dashboard crÃ©Ã© (Image: `ghcr.io/username/openclassrooms-ml-ops-dashboard:latest`)
- [ ] Web Service MLflow crÃ©Ã© (Image: `ghcr.io/username/openclassrooms-ml-ops-mlflow:latest`)
- [ ] Variables d'env configurÃ©es sur chaque service Render (`API_URL`, `MLFLOW_URL` pour Dashboard)
- [ ] (Optionnel) API Key Render gÃ©nÃ©rÃ©e et Service IDs copiÃ©s
- [ ] (Optionnel) Secrets GitHub configurÃ©s (si dÃ©ploiement automatique souhaitÃ© - non actif actuellement)
- [ ] (Optionnel) Variables GitHub configurÃ©es (URLs de dÃ©ploiement)
- [ ] Premier dÃ©ploiement manuel rÃ©ussi (clic "Manual Deploy")
- [ ] API rÃ©pond sur `/health` (modÃ¨les chargÃ©s)
- [ ] Dashboard accessible avec statistiques descriptives dans la sidebar
- [ ] MLflow UI accessible
- [ ] Workflow CI/CD testÃ© (push â†’ tests â†’ build images â†’ GHCR)
- [ ] Processus de dÃ©ploiement manuel testÃ©
- [ ] URLs finales documentÃ©es

**FÃ©licitations ! Votre pipeline CI/CD avec dÃ©ploiement manuel sur Render est opÃ©rationnel ! ğŸ‰**

---

## ğŸ” RÃ©capitulatif des Changements RÃ©cents

### âœ… ModÃ¨les inclus dans l'API
- Les modÃ¨les (`lgbm_model.joblib`, `preprocessor.joblib`, `model_config.json`) sont **inclus dans l'image Docker** de l'API
- L'API les charge automatiquement au dÃ©marrage depuis `/app/models/`
- Le health check `/health` vÃ©rifie que les modÃ¨les sont correctement chargÃ©s

### ğŸ“Š Sidebar du Dashboard enrichie
La barre latÃ©rale contient maintenant **4 sections** :
1. **ğŸ”— Navigation & Services** : Liens vers MLflow et API Docs
2. **ğŸ¥ Ã‰tat des Services** : Statut en temps rÃ©el de l'API et MLflow
3. **ğŸ¤– ModÃ¨le ML** : Seuil optimal et dÃ©tails techniques
4. **ğŸ“Š Statistiques Dataset** (NOUVEAU) :
   - MÃ©triques gÃ©nÃ©rales (nombre clients, variables, taux de dÃ©faut)
   - Statistiques financiÃ¨res (revenu, crÃ©dit)
   - Statistiques dÃ©mographiques (Ã¢ge, genre, enfants)
   - Scores externes (EXT_SOURCE_1, 2, 3)

### ğŸ”„ Workflow CD SimplifiÃ©
- **Avant** : CI/CD avec dÃ©ploiement automatique via API Render (nÃ©cessitait secrets)
- **Maintenant** : 
  - CI exÃ©cute les tests
  - CD build les images Docker et les push vers GHCR
  - **DÃ©ploiement MANUEL** sur Render (clic "Manual Deploy")
- **Avantages** : Plus simple, pas de secrets Ã  configurer, compatible avec tier gratuit Render
