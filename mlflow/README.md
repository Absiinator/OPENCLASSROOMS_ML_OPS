# MLflow UI Server

Service de suivi des expÃ©rimentations Machine Learning avec MLflow.

## ğŸ“‹ Description

Ce conteneur Docker dÃ©ploie une interface MLflow UI pour visualiser et comparer les expÃ©rimentations ML du projet Home Credit Scoring.

## ğŸš€ DÃ©ploiement

### Local

```bash
# Depuis la racine du projet
docker build -f mlflow/Dockerfile -t home-credit-mlflow .
docker run -p 5000:5000 home-credit-mlflow
```

AccÃ©der Ã  : http://localhost:5000

### Production (Render)

Le dÃ©ploiement est automatique via GitHub Actions (`.github/workflows/deploy.yml`).

L'image est construite et poussÃ©e vers GHCR, puis dÃ©ployÃ©e sur Render.

## ğŸ“Š Contenu

### Runs MLflow

Le conteneur inclut les runs MLflow du projet :
- `mlruns/` : Runs du projet principal
- MÃ©triques : AUC, F1, Precision, Recall, Business Cost
- Artefacts : ModÃ¨les, rapports, graphiques

### Configuration

Variables d'environnement :
- `PORT` : Port d'Ã©coute (dÃ©faut: 5000)
- `MLFLOW_TRACKING_URI` : Backend store (`/app/mlruns`)
- `MLFLOW_BACKEND_STORE_URI` : Alias du tracking URI

**Configuration Render (tier gratuit)** :
- 1 worker (au lieu de 4) pour Ã©conomiser la RAM (512MB disponibles)
- Timeout augmentÃ© Ã  120s pour Ã©viter les WORKER TIMEOUT
- DÃ©pendances minimales (pas de boto3/psycopg2)

## ğŸ” FonctionnalitÃ©s

L'interface MLflow UI permet de :
- ğŸ“Š Visualiser les mÃ©triques d'entraÃ®nement
- ğŸ” Comparer les diffÃ©rents runs
- ğŸ“ˆ Tracer les courbes d'apprentissage
- ğŸ“¦ GÃ©rer les versions de modÃ¨les
- ğŸ“¥ TÃ©lÃ©charger les artefacts

## ğŸ› ï¸ DÃ©pendances

Voir [requirements.txt](requirements.txt) :
- `mlflow==2.9.2` : Framework MLflow (version lÃ©gÃ¨re, sans boto3/psycopg2 pour Ã©conomiser la RAM)

## âš¡ Optimisations pour le Tier Gratuit Render (512MB RAM)

### StratÃ©gie d'optimisation

Le Dockerfile utilise **`mlflow ui`** (Flask simple) au lieu de **`mlflow server`** (Gunicorn avec multiple workers):

| Configuration | Consommation RAM | DÃ©tail |
|---------------|-----------------|--------|
| **mlflow ui** (actuel) | ~150-200 MB | Flask simple, pas de Gunicorn |
| mlflow server --workers 1 | ~250-300 MB | Gunicorn + 1 worker = encore trop lourd |
| mlflow server (dÃ©faut) | ~400-500 MB | Gunicorn + 4 workers = **dÃ©passement RAM** |

**BÃ©nÃ©fice** : mlflow ui tient facilement dans les 512MB du tier gratuit sans crashes.

### Configuration appliquÃ©e

```dockerfile
# Dockerfile: utilisation de mlflow ui (ultra-lÃ©ger)
CMD ["mlflow", "ui", "--host", "0.0.0.0", "--port", "${PORT}", "--backend-store-uri", "/app/mlruns"]
```

Aucune configuration Gunicorn nÃ©cessaire (mlflow ui utilise Flask directement).

## ğŸ“ Notes

- Les runs MLflow du dossier `mlruns/` local sont copiÃ©s dans l'image Docker lors du build
- **Tier gratuit Render** : 512MB RAM, service arrÃªtÃ© aprÃ¨s 15 min d'inactivitÃ©
- **Optimisations appliquÃ©es** :
  - âœ… `mlflow ui` au lieu de `mlflow server` (Ã©conomise ~100-150MB)
  - âœ… DÃ©pendances minimales (mlflow v2.9.2 sans extras)
  - âœ… Pas de workers multiples ou timeouts problÃ©matiques
- Les runs sont accessibles en **lecture seule** - les nouvelles expÃ©riences ne seront pas persistÃ©es (tier gratuit)

## ğŸ”§ DÃ©pannage

### "Out of Memory" ou "SIGKILL"

**Si vous voyez ces erreurs en production** :
1. VÃ©rifiez que le Dockerfile utilise `mlflow ui` (pas `mlflow server --workers N`)
2. VÃ©rifiez la RAM allouÃ©e (512MB = limite du tier gratuit)
3. Attendez 1-2 min au dÃ©marrage (premier chargement est lent)

**Solution** : Upgrade vers un plan payant si vous avez vraiment besoin de multiple workers.
