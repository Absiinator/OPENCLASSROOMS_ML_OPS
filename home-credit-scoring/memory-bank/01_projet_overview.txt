================================================================================
                   HOME CREDIT SCORING - VUE D'ENSEMBLE DU PROJET
================================================================================
Date de creation: 2026-01-03
Objectif: Fournir un resume complet du projet pour faciliter la comprehension

--------------------------------------------------------------------------------
1. CONTEXTE METIER
--------------------------------------------------------------------------------
Entreprise: Pret a depenser (societe financiere)
Mission: Construire un outil de scoring credit pour:
  - Calculer la probabilite de defaut de paiement d'un client
  - Classifier les demandes en credit accorde ou refuse
  - Permettre la transparence des decisions aux charges de relation client

Dataset: Home Credit Default Risk (Kaggle)
  - application_train.csv: 307,511 demandes avec TARGET (0=pas defaut, 1=defaut)
  - application_test.csv: 48,744 demandes sans TARGET
  - Tables auxiliaires: bureau, previous_application, installments, POS_CASH, credit_card

Desequilibre des classes:
  - Non-defaut (0): ~92%
  - Defaut (1): ~8%
  - Ratio: environ 11:1

--------------------------------------------------------------------------------
2. COUT METIER ASYMETRIQUE
--------------------------------------------------------------------------------
Le projet prend en compte un cout metier specifique:
  - Faux Negatif (FN): Cout = 10 (client en defaut accepte = perte de capital)
  - Faux Positif (FP): Cout = 1 (bon client refuse = manque a gagner)

Implication: Un FN coute 10x plus qu'un FP
  -> Le modele doit etre plus prudent pour detecter les defauts
  -> Optimisation du seuil de decision basee sur ce cout metier

--------------------------------------------------------------------------------
3. ARCHITECTURE DU PROJET
--------------------------------------------------------------------------------
home-credit-scoring/
  api/             API FastAPI de scoring (deploiement cloud)
  data/            Donnees CSV (non versionnees sur Git)
  models/          Modeles entraines (lgbm_model.joblib, preprocessor.joblib)
  notebooks/       4 notebooks Jupyter pour l'analyse et l'entrainement
  reports/         Rapports generes (graphiques, HTML Evidently)
  scripts/         Scripts utilitaires (download_data.py)
  src/             Code source principal (preprocessing, train, metrics, etc.)
  streamlit_app/   Interface utilisateur dashboard
  tests/           Tests unitaires Pytest
  .github/         CI/CD avec GitHub Actions
  memory-bank/     Fichiers de memoire pour le projet

--------------------------------------------------------------------------------
4. PIPELINE DE TRAITEMENT
--------------------------------------------------------------------------------
Etape 1: EDA (01_EDA.ipynb)
  - Analyse de la distribution TARGET
  - Identification des valeurs manquantes
  - Analyse des variables numeriques et categorielles
  - Correlations avec la TARGET

Etape 2: Preprocessing (02_Preprocessing_Features.ipynb)
  - Feature engineering sur application (ratios, conversions)
  - Agregation des tables auxiliaires (bureau, previous_app, etc.)
  - Encodage LabelEncoder pour variables categorielles
  - Imputation mediane des valeurs manquantes
  - Suppression colonnes avec >80% NaN

Etape 3: Training avec MLflow (03_Model_Training_MLflow.ipynb)
  - Configuration MLflow tracking
  - Entrainement LightGBM avec class_weight='balanced'
  - Optimisation du seuil selon cout metier
  - Logging des parametres, metriques et artifacts
  - Enregistrement dans le Model Registry

Etape 4: Drift Detection (04_Drift_Evidently.ipynb)
  - Analyse Data Drift entre train et test
  - Generation rapport HTML Evidently
  - Detection des features qui driftent

--------------------------------------------------------------------------------
5. MODELE RETENU
--------------------------------------------------------------------------------
Algorithme: LightGBM (Light Gradient Boosting Machine)
  - Type: Gradient boosting sur arbres de decision
  - Avantage: Rapide, performant, gere bien le desequilibre

Hyperparametres cles:
  - num_leaves: 31
  - learning_rate: 0.05
  - n_estimators: 500
  - class_weight: 'balanced'
  - early_stopping_rounds: 50

Resultats obtenus:
  - AUC: 0.7683 (< 0.82, pas d'overfitting)
  - Seuil optimal: 0.44 (vs 0.5 par defaut)
  - Reduction du cout metier: 1.2% vs seuil standard

--------------------------------------------------------------------------------
6. API ET DEPLOIEMENT
--------------------------------------------------------------------------------
Framework: FastAPI
Endpoints:
  - GET /health: Verification etat API
  - POST /predict: Prediction individuelle
  - POST /predict/batch: Predictions en batch
  - POST /predict/explain: Prediction avec explications
  - GET /model/info: Informations du modele
  - GET /model/features: Liste des features

Deploiement recommande: Render (gratuit)
  - Dockerfile fourni
  - GitHub Actions pour CI/CD
  - Variables d'environnement documentees

--------------------------------------------------------------------------------
7. DASHBOARD STREAMLIT
--------------------------------------------------------------------------------
Fonctionnalites:
  - Saisie manuelle des caracteristiques client
  - Affichage du score et de la probabilite
  - Jauge visuelle du risque
  - Explications SHAP des predictions
  - Import de fichiers CSV pour predictions batch
  - Documentation integree

Accessibilite WCAG:
  - Contraste suffisant
  - Textes alternatifs
  - Taille de texte ajustable
  - Couleurs non seules pour transmettre l'information

================================================================================
