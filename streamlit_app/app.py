"""
Dashboard Streamlit - Home Credit Scoring
=========================================

Interface utilisateur pour le scoring de cr√©dit.
Version refactoris√©e avec modules s√©par√©s.

Fonctionnalit√©s (selon exigences) :
- Visualiser le score, probabilit√© et interpr√©tation intelligible
- Informations descriptives du client
- Comparaison avec l'ensemble des clients via graphiques
- Accessibilit√© WCAG (contrastes, labels, navigation)
- Rapport de Data Drift (Evidently)
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import os
import sys
import json
import urllib.request
import urllib.error
import re
from pathlib import Path
from typing import Dict, Any, Optional, List

# Ajouter le r√©pertoire courant au path Python
sys.path.insert(0, str(Path(__file__).parent))

# Import des modules locaux
import api_client
import constants

check_api_health = api_client.check_api_health
get_model_info = api_client.get_model_info
predict_client = api_client.predict_client
explain_prediction = api_client.explain_prediction
get_feature_importance = api_client.get_feature_importance
API_URL = api_client.API_URL

from constants import (
    REQUIRED_FEATURES,
    FEATURE_EXPLANATIONS,
    MODEL_CONFIG,
    get_default_features,
    calculate_ratios,
    get_risk_category,
    get_risk_color
)

# ============================================
# Configuration de la page
# ============================================
st.set_page_config(
    page_title="Home Credit Scoring",
    page_icon="üè¶",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ============================================
# CSS pour l'accessibilit√© WCAG
# ============================================
st.markdown("""
<style>
    /* Contrastes √©lev√©s pour l'accessibilit√© WCAG AA */
    .stMetric label { color: #1a1a1a !important; font-weight: 600 !important; }
    .stMetric [data-testid="stMetricValue"] { color: #0a0a0a !important; font-size: 1.5rem !important; }
    
    /* Focus visible pour navigation clavier */
    button:focus, input:focus, select:focus, a:focus {
        outline: 3px solid #005fcc !important;
        outline-offset: 2px !important;
    }
    
    /* Indicateurs visuels clairs avec patterns */
    .risk-low { background-color: #d4edda !important; color: #155724 !important; padding: 1rem; border-radius: 0.5rem; border-left: 5px solid #28a745; }
    .risk-high { background-color: #f8d7da !important; color: #721c24 !important; padding: 1rem; border-radius: 0.5rem; border-left: 5px solid #dc3545; }
</style>
""", unsafe_allow_html=True)

# ============================================
# Variables globales
# ============================================
MLFLOW_URL = os.getenv("MLFLOW_URL", "http://localhost:5000")
GITHUB_REPO_URL = os.getenv(
    "GITHUB_REPO_URL",
    "https://github.com/Absiinator/OPENCLASSROOMS_ML_OPS"
).rstrip("/")
if GITHUB_REPO_URL.endswith(".git"):
    GITHUB_REPO_URL = GITHUB_REPO_URL[:-4]

# Chemins pour donn√©es et rapports
if os.path.exists("/app/data"):
    PROJECT_ROOT = "/app"
else:
    PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))

DRIFT_REPORT_PATH = os.path.join(PROJECT_ROOT, "reports", "evidently_full_report.html")
DATA_PATH = os.path.join(PROJECT_ROOT, "data", "application_train.csv")
FEATURE_IMPORTANCE_PATH = os.path.join(PROJECT_ROOT, "reports", "feature_importance.csv")
EXIGENCE_PATH = os.path.join(PROJECT_ROOT, "exigence.txt")
MODEL_CONFIG_PATH = os.path.join(PROJECT_ROOT, "models", "model_config.json")


def github_blob(path: str) -> str:
    """Construit un lien GitHub vers un fichier du repo."""
    clean_path = path.lstrip("/")
    return f"{GITHUB_REPO_URL}/blob/main/{clean_path}"


def github_tree(path: str) -> str:
    """Construit un lien GitHub vers un dossier du repo."""
    clean_path = path.lstrip("/")
    return f"{GITHUB_REPO_URL}/tree/main/{clean_path}"


def resolve_github_link(target: str) -> str:
    """R√©sout un lien GitHub √† partir d'un chemin interne ou d'une URL compl√®te."""
    if target.startswith("http://") or target.startswith("https://"):
        return target
    if target.startswith("dir:"):
        return github_tree(target.replace("dir:", "", 1))
    return github_blob(target)


# ============================================
# Fonctions utilitaires
# ============================================

@st.cache_data(ttl=3600, show_spinner=False)
def load_reference_data() -> pd.DataFrame:
    """Charge les donn√©es de r√©f√©rence pour comparaison (cache 1h)."""
    if os.path.exists(DATA_PATH):
        try:
            df = pd.read_csv(DATA_PATH, nrows=10000)
            return df
        except Exception:
            pass
    return pd.DataFrame()


@st.cache_data(ttl=3600, show_spinner=False)
def load_top_features_from_report(top_n: int = 15) -> List[str]:
    """Charge les features les plus importantes depuis le rapport (notebooks)."""
    candidates = []
    if os.path.exists(FEATURE_IMPORTANCE_PATH):
        candidates.append(FEATURE_IMPORTANCE_PATH)

    # Chemin issu du run MLflow (si disponible)
    run_id = None
    if os.path.exists(MODEL_CONFIG_PATH):
        try:
            with open(MODEL_CONFIG_PATH, "r", encoding="utf-8") as f:
                run_id = json.load(f).get("run_id")
        except Exception:
            run_id = None
    if run_id:
        candidates.append(os.path.join(
            PROJECT_ROOT,
            "notebooks",
            "mlruns",
            "446811177754564983",
            run_id,
            "artifacts",
            "feature_importance.csv"
        ))

    # Chemin explicite connu (fallback)
    candidates.append(os.path.join(
        PROJECT_ROOT,
        "notebooks",
        "mlruns",
        "446811177754564983",
        "169b2338d7224da2801ea8dda14d64e3",
        "artifacts",
        "feature_importance.csv"
    ))

    for path in candidates:
        if os.path.exists(path):
            try:
                df = pd.read_csv(path)
                if "feature" in df.columns and "importance" in df.columns:
                    df = df.sort_values("importance", ascending=False)
                    return df["feature"].head(top_n).tolist()
            except Exception:
                continue
    return []


CE_EVIDENCE = [
    {
        "title": "Strat√©gie de mod√©lisation",
        "items": [
            {
                "id": "CE1",
                "text": "Variables cat√©gorielles transform√©es (encodage).",
                "links": [
                    ("Notebook 02", "notebooks/02_Preprocessing_Features.ipynb"),
                    ("Pr√©processing", "src/preprocessing.py")
                ],
            },
            {
                "id": "CE2",
                "text": "Cr√©ation de nouvelles variables (feature engineering).",
                "links": [
                    ("Notebook 02", "notebooks/02_Preprocessing_Features.ipynb"),
                    ("Rapport features", "reports/new_features_correlations.png")
                ],
            },
            {
                "id": "CE3",
                "text": "Transformations math√©matiques selon les distributions.",
                "links": [
                    ("Notebook 02", "notebooks/02_Preprocessing_Features.ipynb")
                ],
            },
            {
                "id": "CE4",
                "text": "Normalisation lorsque n√©cessaire.",
                "links": [
                    ("Notebook 02", "notebooks/02_Preprocessing_Features.ipynb"),
                    ("Pr√©processing", "src/preprocessing.py")
                ],
            },
            {
                "id": "CE5",
                "text": "Strat√©gie d‚Äô√©laboration du mod√®le align√©e au besoin m√©tier.",
                "links": [
                    ("Notebook 03", "notebooks/03_Model_Training_MLflow.ipynb"),
                    ("Support soutenance", "presentation_outline.txt")
                ],
            },
            {
                "id": "CE6",
                "text": "Choix de la variable cible pertinente.",
                "links": [
                    ("Notebook 01", "notebooks/01_EDA.ipynb")
                ],
            },
            {
                "id": "CE7",
                "text": "V√©rification du data leakage.",
                "links": [
                    ("Notebook 01", "notebooks/01_EDA.ipynb"),
                    ("Notebook 03", "notebooks/03_Model_Training_MLflow.ipynb")
                ],
            },
            {
                "id": "CE8",
                "text": "Tests d‚Äôalgorithmes (lin√©aire & non‚Äëlin√©aire).",
                "links": [
                    ("Notebook 03", "notebooks/03_Model_Training_MLflow.ipynb")
                ],
            },
        ],
    },
    {
        "title": "√âvaluation des performances",
        "items": [
            {
                "id": "CE1",
                "text": "M√©trique adapt√©e + score m√©tier (FN/FP).",
                "links": [
                    ("Metrics", "src/metrics.py"),
                    ("Notebook 03", "notebooks/03_Model_Training_MLflow.ipynb"),
                    ("Rapport m√©triques", "reports/metrics_report.txt")
                ],
            },
            {
                "id": "CE2",
                "text": "Autres indicateurs (ROC, confusion, etc.).",
                "links": [
                    ("ROC", "reports/roc_curve.png"),
                    ("Confusion", "reports/confusion_matrix.png"),
                    ("Rapport m√©triques", "reports/metrics_report.txt")
                ],
            },
            {
                "id": "CE3",
                "text": "S√©paration train/test pour l‚Äô√©valuation.",
                "links": [
                    ("Notebook 03", "notebooks/03_Model_Training_MLflow.ipynb"),
                    ("Entra√Ænement", "src/train.py")
                ],
            },
            {
                "id": "CE4",
                "text": "Mod√®le de r√©f√©rence (Dummy).",
                "links": [
                    ("Notebook 03", "notebooks/03_Model_Training_MLflow.ipynb")
                ],
            },
            {
                "id": "CE5",
                "text": "Prise en compte du d√©s√©quilibre des classes.",
                "links": [
                    ("Notebook 03", "notebooks/03_Model_Training_MLflow.ipynb"),
                    ("Entra√Ænement", "src/train.py")
                ],
            },
            {
                "id": "CE6",
                "text": "Optimisation des hyper‚Äëparam√®tres.",
                "links": [
                    ("Notebook 03", "notebooks/03_Model_Training_MLflow.ipynb")
                ],
            },
            {
                "id": "CE7",
                "text": "Validation crois√©e (Grid/Random Search).",
                "links": [
                    ("Notebook 03", "notebooks/03_Model_Training_MLflow.ipynb")
                ],
            },
            {
                "id": "CE8",
                "text": "R√©sultats pr√©sent√©s du simple au complexe + choix final.",
                "links": [
                    ("Notebook 03", "notebooks/03_Model_Training_MLflow.ipynb"),
                    ("Support soutenance", "presentation_outline.txt")
                ],
            },
            {
                "id": "CE9",
                "text": "Feature importance globale et locale.",
                "links": [
                    ("Importance globale", "reports/feature_importance.csv"),
                    ("Top 30", "reports/feature_importance_top30.png"),
                    ("Dashboard (local)", "streamlit_app/app.py")
                ],
            },
        ],
    },
    {
        "title": "Pipeline d‚Äôentra√Ænement & registry",
        "items": [
            {
                "id": "CE1",
                "text": "Pipeline d‚Äôentra√Ænement reproductible.",
                "links": [
                    ("Entra√Ænement", "src/train.py"),
                    ("Pr√©processing", "src/preprocessing.py"),
                    ("Notebook 03", "notebooks/03_Model_Training_MLflow.ipynb")
                ],
            },
            {
                "id": "CE2",
                "text": "S√©rialisation & stockage des mod√®les.",
                "links": [
                    ("Mod√®les", "models/model_config.json"),
                    ("Registry MLflow", "dir:notebooks/mlruns")
                ],
            },
            {
                "id": "CE3",
                "text": "Mesures & r√©sultats formalis√©s pour comparaison.",
                "links": [
                    ("Rapport m√©triques", "reports/metrics_report.txt"),
                    ("Registry MLflow", "dir:notebooks/mlruns")
                ],
            },
        ],
    },
    {
        "title": "Versioning du code",
        "items": [
            {
                "id": "CE1",
                "text": "Repo versionn√© Git + GitHub.",
                "links": [
                    ("GitHub", "https://github.com/Absiinator/OPENCLASSROOMS_ML_OPS")
                ],
            },
            {
                "id": "CE2",
                "text": "Historique de commits (versions distinctes).",
                "links": [
                    ("Commits", "https://github.com/Absiinator/OPENCLASSROOMS_ML_OPS/commits/main")
                ],
            },
            {
                "id": "CE3",
                "text": "Packages & versions list√©s.",
                "links": [
                    ("environment.yml", "environment.yml"),
                    ("pyproject.toml", "pyproject.toml"),
                    ("API requirements", "api/requirements.txt")
                ],
            },
            {
                "id": "CE4",
                "text": "Fichier introductif & structure du projet.",
                "links": [
                    ("README", "README.md"),
                    ("README API", "api/README.md"),
                    ("README Dashboard", "streamlit_app/README.md")
                ],
            },
            {
                "id": "CE5",
                "text": "Scripts comment√©s pour r√©utilisation.",
                "links": [
                    ("Code source", "dir:src"),
                    ("API", "api/main.py")
                ],
            },
        ],
    },
    {
        "title": "D√©ploiement continu de l‚ÄôAPI",
        "items": [
            {
                "id": "CE1",
                "text": "Pipeline CI/CD d√©fini.",
                "links": [
                    ("Workflow", ".github/workflows/ci-cd.yml"),
                    ("Blueprint", "render.yaml")
                ],
            },
            {
                "id": "CE2",
                "text": "API d√©ploy√©e renvoie une pr√©diction.",
                "links": [
                    ("API", "api/main.py"),
                    ("README API", "api/README.md")
                ],
            },
            {
                "id": "CE3",
                "text": "D√©ploiement Cloud automatis√©.",
                "links": [
                    ("render.yaml", "render.yaml"),
                    ("Guide Render", "RENDER_SETUP.md")
                ],
            },
            {
                "id": "CE4",
                "text": "Tests unitaires automatis√©s.",
                "links": [
                    ("Tests", "dir:tests"),
                    ("Workflow", ".github/workflows/ci-cd.yml")
                ],
            },
            {
                "id": "CE5",
                "text": "API ind√©pendante du dashboard.",
                "links": [
                    ("API", "dir:api"),
                    ("Dashboard", "dir:streamlit_app"),
                    ("Blueprint", "render.yaml")
                ],
            },
        ],
    },
    {
        "title": "Suivi de performance & drift",
        "items": [
            {
                "id": "CE1",
                "text": "Strat√©gie de suivi (data drift).",
                "links": [
                    ("Notebook 04", "notebooks/04_Drift_Evidently.ipynb")
                ],
            },
            {
                "id": "CE2",
                "text": "Simulation + rapport Evidently.",
                "links": [
                    ("Rapport", "reports/evidently_full_report.html"),
                    ("Notebook 04", "notebooks/04_Drift_Evidently.ipynb")
                ],
            },
            {
                "id": "CE3",
                "text": "Analyse stabilit√© + actions propos√©es.",
                "links": [
                    ("Notebook 04", "notebooks/04_Drift_Evidently.ipynb"),
                    ("Rapport", "reports/evidently_full_report.html")
                ],
            },
        ],
    },
]


def render_ce_checklist() -> None:
    """Affiche la checklist CE avec preuves GitHub."""
    st.markdown("### ‚úÖ Conformit√© CE (preuves GitHub)")
    with st.expander("Voir la checklist CE", expanded=False):
        for section in CE_EVIDENCE:
            st.markdown(f"**{section['title']}**")
            for item in section["items"]:
                links = []
                for label, target in item.get("links", []):
                    url = resolve_github_link(target)
                    links.append(f"[{label}]({url})")
                links_md = " ‚Ä¢ ".join(links) if links else "‚Äî"
                st.markdown(f"- **{item['id']}** {item['text']} ‚Äî {links_md}")


def interpret_score(probability: float, threshold: float) -> dict:
    """G√©n√®re une interpr√©tation textuelle pour non-experts."""
    if probability < threshold:
        decision = "ACCORD√â"
        if probability < threshold * 0.5:
            confidence = "tr√®s √©lev√©e"
            explanation = "Profil tr√®s favorable. Risque de d√©faut minimal."
        else:
            confidence = "mod√©r√©e"
            explanation = "Profil acceptable avec quelques points de vigilance."
    else:
        decision = "REFUS√â"
        if probability > threshold * 1.5:
            confidence = "tr√®s √©lev√©e"
            explanation = "Profil √† risque significatif. D√©faut de paiement probable."
        else:
            confidence = "mod√©r√©e"
            explanation = "Profil l√©g√®rement au-dessus du seuil de risque."
    
    return {
        "decision": decision,
        "confidence": confidence,
        "explanation": explanation,
        "probability_text": f"{probability*100:.1f}%",
        "threshold_text": f"{threshold*100:.1f}%"
    }


def get_feature_explanation(feature_name: str) -> str:
    """Retourne une explication en langage naturel d'une feature."""
    return FEATURE_EXPLANATIONS.get(feature_name, get_feature_label(feature_name))


FEATURE_LABELS = {k: v.get("label", k) for k, v in REQUIRED_FEATURES.items()}

# Libell√©s explicites pour les colonnes "brutes" du dataset
FEATURE_LABEL_OVERRIDES = {
    "SK_ID_CURR": "ID client",
    "TARGET": "D√©faut (cible)",
    "NAME_CONTRACT_TYPE": "Type de contrat",
    "CODE_GENDER": "Genre",
    "FLAG_OWN_CAR": "Poss√®de une voiture",
    "FLAG_OWN_REALTY": "Propri√©taire immobilier",
    "NAME_TYPE_SUITE": "Type d‚Äôaccompagnement",
    "NAME_INCOME_TYPE": "Type de revenu",
    "NAME_EDUCATION_TYPE": "Niveau d‚Äô√©ducation",
    "NAME_FAMILY_STATUS": "Statut familial",
    "NAME_HOUSING_TYPE": "Type de logement",
    "REGION_POPULATION_RELATIVE": "Population relative de la r√©gion",
    "DAYS_BIRTH": "√Çge (jours)",
    "DAYS_EMPLOYED": "Anciennet√© emploi (jours)",
    "DAYS_REGISTRATION": "Jours depuis inscription",
    "DAYS_ID_PUBLISH": "Jours depuis publication ID",
    "OWN_CAR_AGE": "√Çge du v√©hicule (ann√©es)",
    "FLAG_MOBIL": "T√©l√©phone mobile fourni",
    "FLAG_EMP_PHONE": "T√©l√©phone employeur fourni",
    "FLAG_WORK_PHONE": "T√©l√©phone travail fourni",
    "FLAG_CONT_MOBILE": "T√©l√©phone mobile joignable",
    "FLAG_PHONE": "T√©l√©phone fixe fourni",
    "FLAG_EMAIL": "Email fourni",
    "CNT_FAM_MEMBERS": "Nombre de membres du foyer",
    "REGION_RATING_CLIENT": "Note de la r√©gion",
    "REGION_RATING_CLIENT_W_CITY": "Note r√©gion (avec ville)",
    "WEEKDAY_APPR_PROCESS_START": "Jour de la semaine de la demande",
    "HOUR_APPR_PROCESS_START": "Heure de la demande",
    "REG_REGION_NOT_LIVE_REGION": "R√©gion d‚Äôenregistrement ‚â† r√©sidence",
    "REG_REGION_NOT_WORK_REGION": "R√©gion d‚Äôenregistrement ‚â† travail",
    "LIVE_REGION_NOT_WORK_REGION": "R√©gion r√©sidence ‚â† travail",
    "REG_CITY_NOT_LIVE_CITY": "Ville d‚Äôenregistrement ‚â† r√©sidence",
    "REG_CITY_NOT_WORK_CITY": "Ville d‚Äôenregistrement ‚â† travail",
    "LIVE_CITY_NOT_WORK_CITY": "Ville r√©sidence ‚â† travail",
    "ORGANIZATION_TYPE": "Type d‚Äôorganisation",
    "EXT_SOURCE_1": "Score externe 1",
    "EXT_SOURCE_2": "Score externe 2",
    "EXT_SOURCE_3": "Score externe 3",
    "DAYS_LAST_PHONE_CHANGE": "Jours depuis dernier changement de t√©l√©phone",
    "FONDKAPREMONT_MODE": "Fonds de r√©novation (mode)",
    "HOUSETYPE_MODE": "Type de maison (mode)",
    "WALLSMATERIAL_MODE": "Mat√©riau des murs (mode)",
    "EMERGENCYSTATE_MODE": "√âtat d‚Äôurgence (mode)",
    "OBS_30_CNT_SOCIAL_CIRCLE": "Observations (30 jours)",
    "DEF_30_CNT_SOCIAL_CIRCLE": "D√©fauts (30 jours)",
    "OBS_60_CNT_SOCIAL_CIRCLE": "Observations (60 jours)",
    "DEF_60_CNT_SOCIAL_CIRCLE": "D√©fauts (60 jours)",
    "AMT_REQ_CREDIT_BUREAU_HOUR": "Demandes bureau de cr√©dit (heure)",
    "AMT_REQ_CREDIT_BUREAU_DAY": "Demandes bureau de cr√©dit (jour)",
    "AMT_REQ_CREDIT_BUREAU_WEEK": "Demandes bureau de cr√©dit (semaine)",
    "AMT_REQ_CREDIT_BUREAU_MON": "Demandes bureau de cr√©dit (mois)",
    "AMT_REQ_CREDIT_BUREAU_QRT": "Demandes bureau de cr√©dit (trimestre)",
    "AMT_REQ_CREDIT_BUREAU_YEAR": "Demandes bureau de cr√©dit (ann√©e)",
    "PREV_SK_ID_PREV_COUNT": "Demandes pr√©c√©dentes - Nombre de dossiers",
    "partial_payment_rate": "Taux de paiements partiels",
    "CC_CNT_DRAWINGS_CURRENT_MAX": "Carte de cr√©dit - Nombre de tirages (max)",
    "CC_AMT_BALANCE_MEAN": "Carte de cr√©dit - Solde (moyenne)",
    "PREV_AMT_APPLICATION_MEAN": "Demandes pr√©c√©dentes - Montant demand√© (moyenne)",
    "PREV_CREDIT_APPLICATION_RATIO_MEAN": "Demandes pr√©c√©dentes - Ratio cr√©dit/demande (moyenne)",
    "BUREAU_AMT_CREDIT_SUM_LIMIT_MAX": "Bureau - Limite de cr√©dit cumul√©e (max)",
    "BUREAU_DAYS_CREDIT_MAX": "Bureau - Jours depuis cr√©dit (max)",
    "BUREAU_DAYS_CREDIT_MIN": "Bureau - Jours depuis cr√©dit (min)",
    "NONLIVINGAREA_AVG": "Surface non habitable (moyenne)"
}

FEATURE_LABELS.update(FEATURE_LABEL_OVERRIDES)

STAT_SUFFIXES = {
    "AVG": "moyenne",
    "MEAN": "moyenne",
    "MEDI": "m√©diane",
    "MEDIAN": "m√©diane",
    "MODE": "mode",
    "MAX": "max",
    "MIN": "min",
    "STD": "√©cart type",
    "SUM": "somme",
    "COUNT": "nb",
}

PREFIX_LABELS = {
    "BUREAU": "Bureau",
    "PREV": "Demandes pr√©c√©dentes",
    "POS": "POS Cash",
    "CC": "Carte de cr√©dit",
    "INSTAL": "Remboursements",
}

TOKEN_LABELS = {
    "AMT": "Montant",
    "CNT": "Nombre",
    "DAYS": "Jours",
    "FLAG": "Indicateur",
    "EXT": "Score externe",
    "SOURCE": "Source",
    "REGION": "R√©gion",
    "CITY": "Ville",
    "CREDIT": "Cr√©dit",
    "INCOME": "Revenu",
    "ANNUITY": "Annuit√©",
    "GOODS": "Bien",
    "PRICE": "Prix",
    "BALANCE": "Solde",
    "LIMIT": "Limite",
    "CURRENT": "Actuel",
    "DRAWINGS": "Tirages",
    "PAYMENT": "Paiement",
    "APPLICATION": "Demande",
    "APP": "Demande",
    "PARTIAL": "Partiel",
    "RATE": "Taux",
    "RATIO": "Ratio",
    "SUM": "Somme",
    "RATING": "Note",
    "WEEKDAY": "Jour de semaine",
    "HOUR": "Heure",
    "NAME": "",
    "TYPE": "Type",
    "SUITE": "Accompagnement",
    "EDUCATION": "√âducation",
    "FAMILY": "Familial",
    "HOUSING": "Logement",
    "ORGANIZATION": "Organisation",
    "AGE": "√Çge",
    "OWN": "Possession",
    "CAR": "Voiture",
    "REALTY": "Immobilier",
    "MOBIL": "Mobile",
    "EMAIL": "Email",
    "PHONE": "T√©l√©phone",
    "EMP": "Emploi",
    "WORK": "Travail",
    "CONTACT": "Contact",
    "LIVE": "R√©sidence",
    "NOT": "‚â†",
    "APARTMENTS": "Appartements",
    "BASEMENTAREA": "Surface sous-sol",
    "COMMONAREA": "Surface commune",
    "LANDAREA": "Surface terrain",
    "LIVINGAPARTMENTS": "Appartements habitables",
    "LIVINGAREA": "Surface habitable",
    "NONLIVINGAPARTMENTS": "Appartements non habitables",
    "NONLIVINGAREA": "Surface non habitable",
    "TOTALAREA": "Surface totale",
    "FLOORSMAX": "√âtages max",
    "FLOORSMIN": "√âtages min",
    "ENTRANCES": "Entr√©es",
    "ELEVATORS": "Ascenseurs",
    "YEARS": "Ann√©es",
    "BEGINEXPLUATATION": "D√©but exploitation",
    "BUILD": "Construction",
    "FONDKAPREMONT": "Fonds de r√©novation",
    "HOUSETYPE": "Type de maison",
    "WALLSMATERIAL": "Mat√©riau des murs",
    "EMERGENCYSTATE": "√âtat d‚Äôurgence",
    "OBS": "Observations",
    "DEF": "D√©fauts",
    "SOCIAL": "Social",
    "CIRCLE": "Cercle",
    "DOCUMENT": "Document",
    "REQ": "Demandes",
    "BUREAU": "Bureau",
    "QRT": "Trimestre",
    "YEAR": "Ann√©e",
    "MON": "Mois",
    "WEEK": "Semaine",
    "DAY": "Jour",
    "ID": "ID",
    "SK": "ID",
    "CURR": "Courant",
    "PREV": "Pr√©c√©dent"
}


def _humanize_feature_name(feature_name: str) -> str:
    """Transforme un nom de colonne en libell√© explicite."""
    name = re.sub(r"_x$|_y$", "", feature_name, flags=re.IGNORECASE)
    name = re.sub(r"__+", "_", name)

    # Cas sp√©cifiques (ex: FLAG_DOCUMENT_3)
    doc_match = re.match(r"FLAG_DOCUMENT_(\d+)", name)
    if doc_match:
        return f"Document {doc_match.group(1)} fourni"

    parts = [p for p in name.split("_") if p]
    if not parts:
        return feature_name

    group_label = None
    first = parts[0].upper()
    if first in PREFIX_LABELS:
        group_label = PREFIX_LABELS[first]
        parts = parts[1:]

    stat_suffix = None
    if parts:
        last = parts[-1].upper()
        if last in STAT_SUFFIXES:
            stat_suffix = STAT_SUFFIXES[last]
            parts = parts[:-1]

    label_parts = []
    for part in parts:
        upper = part.upper()
        if upper in TOKEN_LABELS:
            token_label = TOKEN_LABELS[upper]
            if token_label:
                label_parts.append(token_label)
            continue
        if upper.isdigit():
            label_parts.append(upper)
            continue
        label_parts.append(part.replace("-", " ").title())

    label = " ".join(label_parts).strip() if label_parts else feature_name
    if group_label:
        label = f"{group_label} - {label}"
    if stat_suffix:
        label = f"{label} ({stat_suffix})"
    return label


def get_feature_label(feature_name: str) -> str:
    """Retourne un libell√© explicite pour une feature."""
    if feature_name in FEATURE_LABELS:
        return FEATURE_LABELS[feature_name]
    normalized = re.sub(r"_x$|_y$", "", feature_name, flags=re.IGNORECASE)
    if normalized in FEATURE_LABELS:
        return FEATURE_LABELS[normalized]
    return _humanize_feature_name(feature_name)


@st.cache_data(ttl=3600, show_spinner=False)
def compute_reference_stats(df: pd.DataFrame) -> Dict[str, Dict[str, Any]]:
    """Calcule les valeurs par d√©faut (m√©diane/mode) des features de r√©f√©rence."""
    if df is None or df.empty:
        return {"numeric": {}, "categorical": {}}

    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    numeric_medians = df[numeric_cols].median(numeric_only=True).to_dict()

    cat_cols = [c for c in df.columns if c not in numeric_cols]
    cat_modes = {}
    for col in cat_cols:
        try:
            mode = df[col].mode(dropna=True)
            if not mode.empty:
                cat_modes[col] = mode.iloc[0]
        except Exception:
            continue

    return {"numeric": numeric_medians, "categorical": cat_modes}


@st.cache_data(ttl=3600, show_spinner=False)
def get_top_categories(df: pd.DataFrame, column: str, max_items: int = 20) -> List[str]:
    """Retourne les cat√©gories les plus fr√©quentes pour une colonne."""
    if df is None or df.empty or column not in df.columns:
        return []
    series = df[column].dropna().astype(str)
    if series.empty:
        return []
    return series.value_counts().head(max_items).index.tolist()


@st.cache_data(ttl=3600, show_spinner=False)
def compute_numeric_ranges(df: pd.DataFrame) -> Dict[str, Dict[str, Any]]:
    """Calcule min/max et quantiles pour les sliders num√©riques."""
    if df is None or df.empty:
        return {}
    ranges = {}
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    for col in numeric_cols:
        series = df[col].dropna()
        if series.empty:
            continue
        min_val = float(series.min())
        max_val = float(series.max())
        p5 = float(series.quantile(0.05))
        p95 = float(series.quantile(0.95))
        sample = series.head(200)
        is_int = bool(((sample % 1) == 0).all())
        ranges[col] = {
            "min": min_val,
            "max": max_val,
            "p5": p5,
            "p95": p95,
            "is_int": is_int
        }
    return ranges


def is_bounded_numeric(feature_name: str, range_info: Dict[str, Any]) -> bool:
    """D√©termine si une variable num√©rique doit √™tre affich√©e en slider."""
    if not range_info:
        return False
    min_val = range_info.get("min")
    max_val = range_info.get("max")
    if min_val is None or max_val is None:
        return False
    if pd.isna(min_val) or pd.isna(max_val):
        return False
    name = feature_name.upper()
    # 0/1, pourcentages ou ratios
    if 0 <= min_val and max_val <= 1:
        return True
    if any(tok in name for tok in ["RATIO", "RATE", "PERCENT", "SHARE"]) and 0 <= min_val and max_val <= 100:
        return True
    # Petites √©chelles discr√®tes
    if range_info.get("is_int") and 0 <= min_val and max_val <= 5:
        return True
    return False


def detect_multitag(values: List[str]) -> Optional[str]:
    """D√©tecte un s√©parateur multi-tags si pr√©sent dans les valeurs."""
    delimiters = ["|", ";", ",", " / "]
    for d in delimiters:
        with_delim = [v for v in values if d in v]
        if len(with_delim) < 3:
            continue
        tags = []
        for val in with_delim:
            tags.extend(split_multitag_value(val, d))
        unique_tags = set(tags)
        avg_tags = len(tags) / max(len(with_delim), 1)
        # Heuristique: plusieurs valeurs et vrai d√©coupage en tags
        if avg_tags >= 1.5 and len(unique_tags) >= 3:
            return d
    for val in values:
        if (val.startswith("[") and val.endswith("]")) or (val.startswith("(") and val.endswith(")")):
            return ","
    return None


def split_multitag_value(value: str, delimiter: str) -> List[str]:
    """D√©coupe une valeur multi-tags en liste de tags."""
    if value is None:
        return []
    val = str(value).strip()
    if (val.startswith("[") and val.endswith("]")) or (val.startswith("(") and val.endswith(")")):
        val = val[1:-1]
    parts = [p.strip() for p in val.split(delimiter)]
    return [p for p in parts if p]


def render_numeric_inputs(
    features_list: List[str],
    ref_stats: Dict[str, Dict[str, Any]],
    numeric_ranges: Dict[str, Dict[str, Any]],
    key_prefix: str,
    columns: int = 2,
    show_raw_for_bounded: bool = False
) -> None:
    """Affiche des inputs num√©riques (slider si born√©, sinon input)."""
    if not features_list:
        return
    cols = st.columns(columns)
    for idx, feat in enumerate(sorted(features_list, key=get_feature_label)):
        default_val = ref_stats["numeric"].get(feat, 0.0)
        if default_val is None or pd.isna(default_val):
            default_val = 0.0
        current_val = st.session_state.client_features.get(feat, default_val)
        range_info = numeric_ranges.get(feat, {})
        with cols[idx % columns]:
            if is_bounded_numeric(feat, range_info):
                min_val = range_info.get("min", default_val)
                max_val = range_info.get("max", default_val)
                if min_val == max_val:
                    min_val, max_val = default_val - 1, default_val + 1
                step = 1.0 if range_info.get("is_int") else 0.01
                value = st.slider(
                    get_feature_label(feat),
                    min_value=float(min_val),
                    max_value=float(max_val),
                    value=float(current_val) if current_val is not None and not pd.isna(current_val) else float(default_val),
                    step=step,
                    help=get_feature_explanation(feat),
                    key=f"{key_prefix}_slider_{feat}"
                )
                if show_raw_for_bounded:
                    value = st.number_input(
                        f"{get_feature_label(feat)} (valeur)",
                        value=float(value),
                        help=get_feature_explanation(feat),
                        key=f"{key_prefix}_input_{feat}"
                    )
            else:
                value = st.number_input(
                    get_feature_label(feat),
                    value=float(current_val) if current_val is not None and not pd.isna(current_val) else float(default_val),
                    help=get_feature_explanation(feat),
                    key=f"{key_prefix}_input_{feat}"
                )
            st.session_state.client_features[feat] = value


def render_categorical_inputs(
    features_list: List[str],
    ref_data: pd.DataFrame,
    ref_stats: Dict[str, Dict[str, Any]],
    key_prefix: str,
    columns: int = 2
) -> None:
    """Affiche des inputs cat√©goriels (selectbox ou multi-tags)."""
    if not features_list:
        return
    cols = st.columns(columns)
    for idx, feat in enumerate(sorted(features_list, key=get_feature_label)):
        default_val = ref_stats["categorical"].get(feat, "MISSING")
        if default_val is None or pd.isna(default_val):
            default_val = "MISSING"
        choices = get_top_categories(ref_data, feat, max_items=40)
        default_val = str(default_val)
        if default_val not in choices:
            choices = [default_val] + choices
        if "MISSING" not in choices:
            choices.append("MISSING")
        current_val = st.session_state.client_features.get(feat, default_val)
        current_val = str(current_val) if current_val is not None else default_val
        if current_val not in choices:
            choices = [current_val] + choices
        delimiter = detect_multitag(choices)
        with cols[idx % columns]:
            if delimiter:
                with st.expander(get_feature_label(feat), expanded=False):
                    st.caption("S√©lection multiple possible")
                    tag_set = set()
                    for val in choices:
                        tag_set.update(split_multitag_value(val, delimiter))
                    tags = sorted(tag_set)
                    col_a, col_b = st.columns(2)
                    if col_a.button("Tout s√©lectionner", key=f"{key_prefix}_{feat}_select_all"):
                        for tag in tags:
                            st.session_state[f"{key_prefix}_{feat}_tag_{tag}"] = True
                    if col_b.button("Tout d√©s√©lectionner", key=f"{key_prefix}_{feat}_clear_all"):
                        for tag in tags:
                            st.session_state[f"{key_prefix}_{feat}_tag_{tag}"] = False
                    selected = []
                    for tag in tags:
                        key = f"{key_prefix}_{feat}_tag_{tag}"
                        if key not in st.session_state:
                            st.session_state[key] = tag in split_multitag_value(current_val, delimiter)
                        if st.checkbox(tag, key=key):
                            selected.append(tag)
                    if selected:
                        st.session_state.client_features[feat] = delimiter.join(selected)
                    else:
                        st.session_state.client_features[feat] = "MISSING"
            else:
                st.session_state.client_features[feat] = st.selectbox(
                    get_feature_label(feat),
                    options=choices,
                    index=choices.index(current_val),
                    help=get_feature_explanation(feat),
                    key=f"{key_prefix}_select_{feat}"
                )


def check_mlflow_health(url: str) -> bool:
    """V√©rifie si l'UI MLflow est accessible."""
    if not url:
        return False
    try:
        with urllib.request.urlopen(url, timeout=5) as resp:
            return 200 <= resp.status < 400
    except Exception:
        return False


def create_gauge_chart(probability: float, threshold: float) -> go.Figure:
    """Cr√©e une jauge visuelle du score de risque."""
    color = get_risk_color(probability)
    
    fig = go.Figure(go.Indicator(
        mode="gauge+number+delta",
        value=probability * 100,
        number={'suffix': "%", 'font': {'size': 40}},
        delta={'reference': threshold * 100, 'position': "bottom", 'relative': False},
        title={'text': "Probabilit√© de d√©faut", 'font': {'size': 20}},
        gauge={
            'axis': {'range': [0, 100], 'tickwidth': 1},
            'bar': {'color': color},
            'bgcolor': "white",
            'borderwidth': 2,
            'bordercolor': "gray",
            'steps': [
                {'range': [0, 20], 'color': '#d4edda'},
                {'range': [20, 40], 'color': '#fff3cd'},
                {'range': [40, 60], 'color': '#ffeaa7'},
                {'range': [60, 80], 'color': '#f8d7da'},
                {'range': [80, 100], 'color': '#f5c6cb'}
            ],
            'threshold': {
                'line': {'color': "red", 'width': 4},
                'thickness': 0.75,
                'value': threshold * 100
            }
        }
    ))
    
    fig.update_layout(
        height=300,
        margin=dict(l=20, r=20, t=50, b=20),
        font={'color': "#1a1a1a"}
    )
    return fig


def create_comparison_chart(
    client_value: float,
    feature_name: str,
    reference_data: pd.DataFrame,
    group_filter: Optional[str] = None
) -> Optional[go.Figure]:
    """Cr√©e un histogramme de comparaison client vs population."""
    if feature_name not in reference_data.columns:
        return None

    data = reference_data[feature_name].dropna()

    if group_filter and group_filter != "Tous les clients":
        if "TARGET" in reference_data.columns:
            if group_filter == "Clients sans d√©faut (TARGET=0)":
                data = reference_data[reference_data["TARGET"] == 0][feature_name].dropna()
            elif group_filter == "Clients en d√©faut (TARGET=1)":
                data = reference_data[reference_data["TARGET"] == 1][feature_name].dropna()

    if data.empty:
        return None

    fig = go.Figure()
    fig.add_trace(go.Histogram(
        x=data,
        name="Distribution",
        opacity=0.7,
        marker_color="#4169E1"
    ))

    label = get_feature_label(feature_name)
    fig.add_vline(
        x=client_value,
        line_dash="dash",
        line_color="#C41E3A",
        line_width=3,
        annotation_text=f"Client: {client_value:.2f}",
        annotation_position="top"
    )

    percentile = (data < client_value).mean() * 100
    fig.update_layout(
        title=f"Distribution de {label} (client au {percentile:.0f}e percentile)",
        xaxis_title=label,
        yaxis_title="Nombre de clients",
        height=400,
        showlegend=False
    )

    return fig


def create_radar_comparison(
    client_features: Dict[str, float],
    reference_data: pd.DataFrame,
    selected_features: List[str]
) -> Optional[go.Figure]:
    """Cr√©e un graphique radar pour comparer plusieurs features."""
    normalized_client = []
    normalized_mean = []
    valid_features = []

    for feat in selected_features:
        if feat in reference_data.columns and feat in client_features:
            if client_features.get(feat) is None or pd.isna(client_features.get(feat)):
                continue
            ref_data = reference_data[feat].dropna()
            if ref_data.empty:
                continue
            min_val, max_val = ref_data.min(), ref_data.max()
            if max_val > min_val:
                client_norm = (client_features[feat] - min_val) / (max_val - min_val)
                mean_norm = (ref_data.mean() - min_val) / (max_val - min_val)
            else:
                client_norm, mean_norm = 0.5, 0.5
            normalized_client.append(client_norm)
            normalized_mean.append(mean_norm)
            valid_features.append(feat)

    if not normalized_client or len(valid_features) < 3:
        return None
    labels = [get_feature_label(f) for f in valid_features]

    fig = go.Figure()
    fig.add_trace(go.Scatterpolar(
        r=normalized_mean + [normalized_mean[0]],
        theta=labels + [labels[0]],
        fill='toself',
        fillcolor='rgba(65, 105, 225, 0.3)',
        line_color='#4169E1',
        name='Moyenne population'
    ))
    fig.add_trace(go.Scatterpolar(
        r=normalized_client + [normalized_client[0]],
        theta=labels + [labels[0]],
        fill='toself',
        fillcolor='rgba(196, 30, 58, 0.3)',
        line_color='#C41E3A',
        name='Client actuel'
    ))

    fig.update_layout(
        polar=dict(radialaxis=dict(visible=True, range=[0, 1])),
        showlegend=True,
        title={'text': "Comparaison multi-crit√®res", 'font': {'size': 16}},
        height=500,
        paper_bgcolor='white'
    )

    return fig


# ============================================
# Interface utilisateur principale
# ============================================

def render_sidebar(reference_data: pd.DataFrame):
    """Affiche la sidebar avec navigation, docs et statuts."""
    with st.sidebar:
        st.title("üè¶ Home Credit")
        st.divider()

        # Navigation
        st.header("üìç Navigation")
        nav_options = [
            ("üéØ Scoring", "scoring"),
            ("üìä Dataset", "dataset"),
            ("üìà Data Drift", "drift"),
            ("üìñ Documentation", "docs")
        ]
        if "current_page" not in st.session_state:
            st.session_state.current_page = "scoring"
        for label, page_key in nav_options:
            btn_type = "primary" if st.session_state.current_page == page_key else "secondary"
            if st.button(label, key=f"nav_{page_key}", use_container_width=True, type=btn_type):
                st.session_state.current_page = page_key
                st.rerun()

        st.divider()

        # Documentation
        st.header("üîó Documentation")
        st.link_button("Swagger", f"{API_URL}/docs", use_container_width=True)
        st.link_button("MLflow UI", MLFLOW_URL, use_container_width=True)
        st.link_button("README Projet", github_blob("README.md"), use_container_width=True)
        st.link_button("Guide Render", github_blob("RENDER_SETUP.md"), use_container_width=True)
        st.link_button("README API", github_blob("api/README.md"), use_container_width=True)
        st.link_button("README Dashboard", github_blob("streamlit_app/README.md"), use_container_width=True)
        st.link_button("Notebooks (dossier)", github_tree("notebooks"), use_container_width=True)
        with st.expander("Notebooks (liens directs)", expanded=False):
            st.link_button("01_EDA", github_blob("notebooks/01_EDA.ipynb"), use_container_width=True)
            st.link_button("02_Preprocessing", github_blob("notebooks/02_Preprocessing_Features.ipynb"), use_container_width=True)
            st.link_button("03_Model_Training", github_blob("notebooks/03_Model_Training_MLflow.ipynb"), use_container_width=True)
            st.link_button("04_Drift", github_blob("notebooks/04_Drift_Evidently.ipynb"), use_container_width=True)
        st.link_button("Repo GitHub", GITHUB_REPO_URL, use_container_width=True)

        st.divider()

        # √âtat des services
        st.header("üè• √âtat")
        api_ok = check_api_health()
        mlflow_ok = check_mlflow_health(MLFLOW_URL)
        drift_exists = os.path.exists(DRIFT_REPORT_PATH)
        st.write(f"{'‚úÖ' if api_ok else '‚ö†Ô∏è'} API: {'OK' if api_ok else 'Hors ligne'}")
        st.write(f"{'‚úÖ' if mlflow_ok else '‚ö†Ô∏è'} MLflow: {'OK' if mlflow_ok else 'Hors ligne'}")
        st.write(f"{'‚úÖ' if drift_exists else '‚ö†Ô∏è'} Drift: {'OK' if drift_exists else 'Absent'}")

        st.divider()

        # Mod√®le
        st.header("ü§ñ Mod√®le")
        model_info = get_model_info()
        if model_info:
            st.write(f"Nom: **{model_info.get('model_name', 'N/A')}**")
            st.write(f"Version: **{model_info.get('version', 'N/A')}**")
            training_date = model_info.get("training_date") or "N/A"
            st.write(f"Date mod√®le: **{training_date}**")
        else:
            st.caption("Infos indisponibles")

        st.divider()
        st.caption("v1.0.0 ‚Ä¢ Home Credit Scoring")


def render_prediction_tab():
    """Onglet principal: Scoring et pr√©diction."""
    st.header("üéØ Scoring de cr√©dit")
    
    # V√©rifier l'API (ne bloque pas la comparaison)
    api_ok = check_api_health()
    if not api_ok:
        st.warning("‚ö†Ô∏è API indisponible. La comparaison reste possible, la pr√©diction est d√©sactiv√©e.")
        st.info(f"API_URL: {API_URL}")

    ref_data = load_reference_data()
    ref_stats = compute_reference_stats(ref_data)
    numeric_ranges = compute_numeric_ranges(ref_data)
    top_from_report = load_top_features_from_report(25)
    important_features = set(top_from_report + list(REQUIRED_FEATURES.keys()))
    
    st.markdown("### Saisie des informations client")
    
    # Initialiser les features avec les valeurs par d√©faut
    if 'client_features' not in st.session_state:
        st.session_state.client_features = get_default_features()
    
    # Formulaire de saisie en colonnes
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("#### üí∞ Finances")
        st.session_state.client_features["AMT_INCOME_TOTAL"] = st.number_input(
            "Revenu annuel (‚Ç¨)",
            min_value=0.0, max_value=10000000.0,
            value=float(st.session_state.client_features.get("AMT_INCOME_TOTAL", 150000)),
            step=10000.0,
            help=FEATURE_EXPLANATIONS.get("AMT_INCOME_TOTAL", "")
        )
        st.session_state.client_features["AMT_CREDIT"] = st.number_input(
            "Montant cr√©dit (‚Ç¨)",
            min_value=0.0, max_value=5000000.0,
            value=float(st.session_state.client_features.get("AMT_CREDIT", 500000)),
            step=10000.0,
            help=FEATURE_EXPLANATIONS.get("AMT_CREDIT", "")
        )
        st.session_state.client_features["AMT_ANNUITY"] = st.number_input(
            "Annuit√© (‚Ç¨/an)",
            min_value=0.0, max_value=500000.0,
            value=float(st.session_state.client_features.get("AMT_ANNUITY", 25000)),
            step=1000.0,
            help=FEATURE_EXPLANATIONS.get("AMT_ANNUITY", "")
        )
        st.session_state.client_features["AMT_GOODS_PRICE"] = st.number_input(
            "Prix du bien (‚Ç¨)",
            min_value=0.0, max_value=5000000.0,
            value=float(st.session_state.client_features.get("AMT_GOODS_PRICE", 450000)),
            step=10000.0,
            help=FEATURE_EXPLANATIONS.get("AMT_GOODS_PRICE", "")
        )
    
    with col2:
        st.markdown("#### üë§ Personnel")
        age_years = st.slider(
            "√Çge (ann√©es)",
            min_value=18, max_value=80,
            value=35,
            help="Converti en jours pour le mod√®le"
        )
        st.session_state.client_features["DAYS_BIRTH"] = -age_years * 365
        
        exp_years = st.slider(
            "Anciennet√© emploi (ann√©es)",
            min_value=0, max_value=50,
            value=5,
            help="Converti en jours pour le mod√®le"
        )
        st.session_state.client_features["DAYS_EMPLOYED"] = -exp_years * 365
        
        st.session_state.client_features["CNT_CHILDREN"] = st.number_input(
            "Nombre d'enfants",
            min_value=0, max_value=20,
            value=int(st.session_state.client_features.get("CNT_CHILDREN", 1))
        )
        
        gender = st.selectbox("Genre", ["Homme", "Femme"])
        st.session_state.client_features["CODE_GENDER_M"] = 1 if gender == "Homme" else 0
        
        st.session_state.client_features["FLAG_OWN_CAR"] = 1 if st.checkbox("Poss√®de une voiture", value=True) else 0
        st.session_state.client_features["FLAG_OWN_REALTY"] = 1 if st.checkbox("Propri√©taire immobilier", value=True) else 0
    
    with col3:
        st.markdown("#### üìä Scores externes")
        st.session_state.client_features["EXT_SOURCE_1"] = st.slider(
            "Score externe 1",
            min_value=0.0, max_value=1.0,
            value=float(st.session_state.client_features.get("EXT_SOURCE_1", 0.5)),
            step=0.01,
            help=FEATURE_EXPLANATIONS.get("EXT_SOURCE_1", "")
        )
        st.session_state.client_features["EXT_SOURCE_2"] = st.slider(
            "Score externe 2",
            min_value=0.0, max_value=1.0,
            value=float(st.session_state.client_features.get("EXT_SOURCE_2", 0.6)),
            step=0.01,
            help=FEATURE_EXPLANATIONS.get("EXT_SOURCE_2", "")
        )
        st.session_state.client_features["EXT_SOURCE_3"] = st.slider(
            "Score externe 3",
            min_value=0.0, max_value=1.0,
            value=float(st.session_state.client_features.get("EXT_SOURCE_3", 0.55)),
            step=0.01,
            help=FEATURE_EXPLANATIONS.get("EXT_SOURCE_3", "")
        )
        st.session_state.client_features["REGION_RATING_CLIENT"] = st.selectbox(
            "Note r√©gion",
            options=[1, 2, 3],
            index=1,
            help="1=faible risque, 3=risque √©lev√©"
        )

    # Variables compl√©mentaires (optionnelles)
    numeric_cols = ref_data.select_dtypes(include=[np.number]).columns.tolist() if not ref_data.empty else []
    categorical_cols = [c for c in ref_data.columns if c not in numeric_cols] if not ref_data.empty else []
    exclude_cols = ["SK_ID_CURR", "TARGET", "index"]
    extra_numeric = [f for f in numeric_cols if f not in exclude_cols and f not in REQUIRED_FEATURES]
    extra_categorical = [f for f in categorical_cols if f not in exclude_cols and f not in REQUIRED_FEATURES]
    if extra_numeric or extra_categorical:
        important_numeric = [f for f in extra_numeric if f in important_features]
        other_numeric = [f for f in extra_numeric if f not in important_features]
        important_cat = [f for f in extra_categorical if f in important_features]
        other_cat = [f for f in extra_categorical if f not in important_features]

        if important_numeric:
            st.subheader("‚≠ê Variables num√©riques importantes (suppl√©mentaires)")
            render_numeric_inputs(
                important_numeric,
                ref_stats,
                numeric_ranges,
                key_prefix="important_num",
                show_raw_for_bounded=True
            )

        if important_cat:
            st.subheader("‚≠ê Variables cat√©gorielles importantes (suppl√©mentaires)")
            render_categorical_inputs(
                important_cat,
                ref_data,
                ref_stats,
                key_prefix="important_cat"
            )

        if other_numeric or other_cat:
            with st.expander("‚ûï Variables avanc√©es (moins importantes)", expanded=False):
                st.caption("Toutes les variables avanc√©es sont affich√©es pour modification directe.")
                if other_numeric:
                    st.markdown("**Variables num√©riques avanc√©es**")
                    render_numeric_inputs(
                        other_numeric,
                        ref_stats,
                        numeric_ranges,
                        key_prefix="other_num"
                    )

                if other_cat:
                    st.markdown("**Variables cat√©gorielles avanc√©es**")
                    render_categorical_inputs(
                        other_cat,
                        ref_data,
                        ref_stats,
                        key_prefix="other_cat"
                    )
    
    # Calculer les ratios automatiquement
    features = calculate_ratios(st.session_state.client_features)
    st.session_state.current_features = features
    
    st.markdown("---")

    # Comparaison population (sans pr√©diction)
    render_comparison_section(features, ref_data, show_header=True)

    st.markdown("---")

    # Bouton de pr√©diction
    if st.button("üîÆ Calculer le score", type="primary", use_container_width=True, disabled=not api_ok):
        with st.spinner("Calcul en cours..."):
            result = predict_client(features)
        
        if result and "error" not in result:
            # Afficher les r√©sultats
            probability = result.get("probability", 0)
            threshold = result.get("threshold", 0.44)
            decision = result.get("decision", "")
            
            # Interpr√©tation
            interpretation = interpret_score(probability, threshold)
            
            # Layout r√©sultats
            res_col1, res_col2 = st.columns([1, 1])
            
            with res_col1:
                # Jauge de risque
                fig_gauge = create_gauge_chart(probability, threshold)
                st.plotly_chart(fig_gauge, use_container_width=True)
            
            with res_col2:
                # D√©cision
                if decision == "ACCEPT√â":
                    st.markdown(f'<div class="risk-low"><h2>‚úÖ {decision}</h2></div>', unsafe_allow_html=True)
                else:
                    st.markdown(f'<div class="risk-high"><h2>‚ùå {decision}</h2></div>', unsafe_allow_html=True)
                
                st.markdown(f"""
                ### Interpr√©tation
                
                - **Probabilit√© de d√©faut**: {interpretation['probability_text']}
                - **Seuil de d√©cision**: {interpretation['threshold_text']}
                - **Confiance**: {interpretation['confidence']}
                
                {interpretation['explanation']}
                """)
            
            # Stocker pour comparaison
            st.session_state.last_prediction = result
            st.session_state.last_features = features

            # R√©sum√© descriptif du client
            st.subheader("üë§ R√©sum√© du profil client")
            profile_col1, profile_col2, profile_col3 = st.columns(3)
            with profile_col1:
                st.markdown("**Situation financi√®re**")
                st.write(f"- Revenu: {features['AMT_INCOME_TOTAL']:,.0f} ‚Ç¨")
                st.write(f"- Cr√©dit demand√©: {features['AMT_CREDIT']:,.0f} ‚Ç¨")
                st.write(f"- Ratio cr√©dit/revenu: {features['CREDIT_INCOME_RATIO']:.2f}")
            with profile_col2:
                st.markdown("**Situation personnelle**")
                age_years = abs(int(features['DAYS_BIRTH'])) // 365
                employed_years = abs(int(features['DAYS_EMPLOYED'])) // 365
                st.write(f"- √Çge: {age_years} ans")
                st.write(f"- Anciennet√© emploi: {employed_years} ans")
                st.write(f"- Enfants: {features['CNT_CHILDREN']}")
            with profile_col3:
                st.markdown("**Scores de cr√©dit**")
                st.write(f"- Score moyen: {features['EXT_SOURCE_MEAN']:.2f}")
                st.write(f"- Propri√©taire: {'Oui' if features['FLAG_OWN_REALTY'] else 'Non'}")
                st.write(f"- V√©hicule: {'Oui' if features['FLAG_OWN_CAR'] else 'Non'}")
            
        else:
            status_code = result.get("status_code") if result else None
            detail = result.get("detail", "Erreur inconnue") if result else "Pas de r√©ponse"
            if isinstance(detail, dict):
                detail = detail.get("detail", detail)
            detail = str(detail)
            if status_code == 404:
                st.error("‚ùå Endpoint API introuvable (404).")
                st.info(f"API_URL: {API_URL}")
                st.info(f"Endpoint attendu: {API_URL}/predict")
            else:
                st.error(f"‚ùå Erreur API ({status_code}): {detail}")


def render_comparison_section(
    features: Dict[str, float],
    ref_data: pd.DataFrame,
    show_header: bool = True
):
    """Section comparaison avec la population."""
    if show_header:
        st.header("üìä Comparaison avec la population")
    if ref_data.empty:
        st.warning("‚ö†Ô∏è Donn√©es de r√©f√©rence non disponibles.")
        return

    st.markdown("""
    **Comparez les caract√©ristiques du client avec l'ensemble de la population ou un groupe de clients similaires.**
    """)

    group_filter = st.selectbox(
        "üéØ Groupe de comparaison",
        ["Tous les clients", "Clients sans d√©faut (TARGET=0)", "Clients en d√©faut (TARGET=1)"],
        help="S√©lectionnez le groupe avec lequel comparer le client"
    )

    numeric_cols = ref_data.select_dtypes(include=[np.number]).columns.tolist()
    categorical_cols = [c for c in ref_data.columns if c not in numeric_cols]
    exclude_cols = ["SK_ID_CURR", "TARGET", "index"]
    numeric_features = [f for f in numeric_cols if f not in exclude_cols]
    categorical_features = [f for f in categorical_cols if f not in exclude_cols]
    available_features = numeric_features + categorical_features

    if not available_features:
        st.warning("Aucune feature comparable disponible.")
        return

    top_from_report = load_top_features_from_report(50)
    priority_features = [f for f in top_from_report if f in available_features]
    for feat in REQUIRED_FEATURES.keys():
        if feat in available_features and feat not in priority_features:
            priority_features.append(feat)
    other_features = [f for f in available_features if f not in priority_features]
    available_features = priority_features + sorted(other_features, key=get_feature_label)
    default_feature = priority_features[0] if priority_features else (available_features[0] if available_features else None)

    tab1, tab2, tab3 = st.tabs([
        "üéØ Vue Radar",
        "üìà Comparaison d√©taill√©e",
        "üìã Statistiques compl√®tes"
    ])

    with tab1:
        st.subheader("üéØ Comparaison multi-crit√®res")
        # Utiliser les features les plus importantes issues du notebook (reports/feature_importance.csv)
        top_from_report = load_top_features_from_report(15)
        default_radar = [f for f in top_from_report if f in numeric_features][:6]
        if len(default_radar) < 3:
            default_radar = [f for f in [
                "EXT_SOURCE_2", "EXT_SOURCE_3", "EXT_SOURCE_1",
                "DAYS_BIRTH", "AMT_CREDIT", "AMT_ANNUITY",
                "AMT_INCOME_TOTAL", "CREDIT_INCOME_RATIO"
            ] if f in numeric_features][:6]

        radar_features = st.multiselect(
            "Caract√©ristiques √† comparer (3-8 recommand√©)",
            numeric_features,
            default=default_radar,
            help="Choisissez jusqu'√† 8 caract√©ristiques pour le radar",
            format_func=get_feature_label
        )

        if radar_features and len(radar_features) >= 3:
            fig_radar = create_radar_comparison(features, ref_data, radar_features)
            if fig_radar:
                st.plotly_chart(fig_radar, use_container_width=True)
            else:
                st.warning("Radar indisponible. V√©rifiez que les valeurs client sont renseign√©es.")
        else:
            st.info("S√©lectionnez au moins 3 caract√©ristiques.")

    with tab2:
        st.subheader("üìà Comparaison d√©taill√©e par caract√©ristique")
        selected_feature = st.selectbox(
            "S√©lectionnez une caract√©ristique",
            available_features,
            help="Voir la distribution et la position du client",
            format_func=get_feature_label,
            index=available_features.index(default_feature) if default_feature in available_features else 0
        )

        st.info(f"**{get_feature_label(selected_feature)}**: {get_feature_explanation(selected_feature)}")
        client_value = features.get(selected_feature)
        if selected_feature in numeric_features:
            if client_value is None or pd.isna(client_value):
                st.warning("Valeur client indisponible pour cette caract√©ristique. Ajoutez-la dans les variables compl√©mentaires.")
            else:
                fig = create_comparison_chart(client_value, selected_feature, ref_data, group_filter)
                if fig:
                    st.plotly_chart(fig, use_container_width=True)
                    ref_col = ref_data[selected_feature].dropna()
                    percentile = (ref_col < client_value).mean() * 100 if len(ref_col) > 0 else 0
                    stat_col1, stat_col2, stat_col3 = st.columns(3)
                    with stat_col1:
                        st.metric("Valeur client", f"{client_value:,.2f}")
                    with stat_col2:
                        st.metric("Moyenne population", f"{ref_col.mean():,.2f}")
                    with stat_col3:
                        st.metric("Percentile", f"{percentile:.0f}%")

                    if percentile < 25:
                        st.warning("‚ö†Ô∏è Client dans les 25% les plus bas.")
                    elif percentile > 75:
                        st.success("‚úÖ Client dans les 25% les plus hauts.")
                    else:
                        st.info("‚ÑπÔ∏è Client dans la moyenne.")
                else:
                    st.warning("Impossible de cr√©er le graphique.")
        else:
            if client_value is None or (isinstance(client_value, float) and pd.isna(client_value)):
                st.warning("Valeur client indisponible pour cette caract√©ristique. Ajoutez-la dans les variables compl√©mentaires.")
            else:
                series = ref_data[selected_feature].dropna().astype(str)
                if series.empty:
                    st.info("Aucune donn√©e disponible pour cette caract√©ristique.")
                else:
                    unique_count = series.nunique()
                    if unique_count > 15:
                        st.info("Trop de cat√©gories pour un graphique lisible.")
                    else:
                        counts = series.value_counts()
                        labels = list(counts.index)
                        values = list(counts.values)
                        client_str = str(client_value)
                        colors = ["#C41E3A" if label == client_str else "#4169E1" for label in labels]
                        fig = go.Figure(go.Bar(x=labels, y=values, marker_color=colors))
                        fig.update_layout(
                            title=f"R√©partition de {get_feature_label(selected_feature)}",
                            xaxis_title="Cat√©gorie",
                            yaxis_title="Nombre de clients",
                            height=400
                        )
                        st.plotly_chart(fig, use_container_width=True)
                        client_pct = (series == client_str).mean() * 100
                        st.info(f"Valeur client: **{client_str}** ‚Ä¢ Fr√©quence: **{client_pct:.1f}%**")

    with tab3:
        st.subheader("üìã Statistiques compl√®tes du client")
        numeric_data = []
        for feat in numeric_features:
            if feat in ref_data.columns:
                client_val = features.get(feat)
                ref_col = ref_data[feat].dropna()
                if len(ref_col) == 0:
                    continue
                percentile = (ref_col < client_val).mean() * 100 if client_val is not None and not pd.isna(client_val) else None
                numeric_data.append({
                    "Caract√©ristique": get_feature_label(feat),
                    "Colonne": feat,
                    "Valeur client": f"{client_val:,.2f}" if client_val is not None and not pd.isna(client_val) else "Non renseign√©",
                    "Moyenne pop.": f"{ref_col.mean():,.2f}",
                    "M√©diane pop.": f"{ref_col.median():,.2f}",
                    "Percentile": f"{percentile:.0f}%" if percentile is not None else "‚Äî",
                })

        if numeric_data:
            st.markdown("**Variables num√©riques**")
            df_numeric = pd.DataFrame(numeric_data)
            st.dataframe(df_numeric, use_container_width=True, hide_index=True)
        else:
            st.info("Aucune statistique num√©rique disponible.")

        cat_data = []
        for feat in categorical_features:
            if feat in ref_data.columns:
                series = ref_data[feat].dropna().astype(str)
                if series.empty:
                    continue
                mode_val = series.mode(dropna=True)
                mode_val = mode_val.iloc[0] if not mode_val.empty else "‚Äî"
                mode_pct = (series == str(mode_val)).mean() * 100 if mode_val != "‚Äî" else 0
                client_val = features.get(feat)
                client_str = str(client_val) if client_val is not None and not (isinstance(client_val, float) and pd.isna(client_val)) else "Non renseign√©"
                client_pct = (series == client_str).mean() * 100 if client_str != "Non renseign√©" else None
                cat_data.append({
                    "Caract√©ristique": get_feature_label(feat),
                    "Colonne": feat,
                    "Valeur client": client_str,
                    "Mode pop.": f"{mode_val}",
                    "Freq. mode": f"{mode_pct:.1f}%",
                    "Freq. client": f"{client_pct:.1f}%" if client_pct is not None else "‚Äî"
                })

        if cat_data:
            st.markdown("**Variables cat√©gorielles**")
            df_cat = pd.DataFrame(cat_data)
            st.dataframe(df_cat, use_container_width=True, hide_index=True)


def render_drift_tab():
    """Onglet rapport de Data Drift (Evidently)."""
    st.header("üìà Analyse du Data Drift")

    st.markdown("""
    ## Rapport Evidently
    
    Le rapport de data drift permet de d√©tecter les d√©rives entre:
    - **Donn√©es d'entra√Ænement** (r√©f√©rence)
    - **Donn√©es de production** (nouvelles donn√©es)
    
    **M√©triques surveill√©es**:
    - Distribution des features
    - Valeurs manquantes
    - Corr√©lations
    - Tests statistiques (Kolmogorov-Smirnov, Chi¬≤)
    """)

    if os.path.exists(DRIFT_REPORT_PATH):
        try:
            with open(DRIFT_REPORT_PATH, 'r', encoding='utf-8') as f:
                html_content = f.read()
            st.markdown("### Rapport complet Evidently")
            st.components.v1.html(html_content, height=1200, scrolling=True)
        except Exception as e:
            st.error(f"Erreur lors du chargement du rapport: {e}")
    else:
        st.warning("üìã Rapport Evidently non disponible.")
        st.info(
            "Le rapport est g√©n√©r√© par le notebook "
            f"[04_Drift_Evidently.ipynb]({github_blob('notebooks/04_Drift_Evidently.ipynb')})."
        )


def render_documentation_tab():
    """Onglet documentation."""
    st.header("üìñ Documentation")
    
    st.markdown("""
    ## Guide d'utilisation
    
    ### üéØ Onglet Scoring
    Saisissez les caract√©ristiques du client pour obtenir:
    - La probabilit√© de d√©faut de paiement
    - La d√©cision (Accord√©/Refus√©)
    - Une interpr√©tation pour non-experts
    
    ### üìä Comparaison (dans l'onglet Scoring)
    Comparez le profil du client avec l'ensemble de la population:
    - Visualisation de la distribution
    - Position du client (percentile)

    ### üìä Onglet Dataset
    Pr√©sente les statistiques cl√©s du jeu de donn√©es (taille, taux de d√©faut, revenus, cr√©dits, scores externes).
    
    ### üìà Onglet Data Drift
    Rapport Evidently analysant la stabilit√© des donn√©es.
    
    ---
    
    ## Features importantes
    
    | Feature | Description | Impact |
    |---------|-------------|--------|
    | EXT_SOURCE_1/2/3 | Scores de cr√©dit externes | Plus √©lev√© = meilleur |
    | CREDIT_INCOME_RATIO | Ratio cr√©dit/revenu | Plus bas = meilleur |
    | DAYS_BIRTH | √Çge (jours n√©gatifs) | Plus √¢g√© = plus stable |
    | AMT_CREDIT | Montant du cr√©dit | - |
    
    ---
    
    ## Seuil de d√©cision
    
    **Seuil optimal: 0.44** (issu de l'optimisation du co√ªt m√©tier)
    
    - Co√ªt Faux N√©gatif (FN): 10 (mauvais client accept√©)
    - Co√ªt Faux Positif (FP): 1 (bon client refus√©)
    
    Le mod√®le minimise: `10 √ó FN + 1 √ó FP`
    """)


def render_dataset_tab():
    """Onglet analyse du dataset."""
    st.header("üìä Analyse du jeu de donn√©es")

    ref_data = load_reference_data()
    if ref_data.empty:
        st.warning("‚ö†Ô∏è Donn√©es de r√©f√©rence non disponibles.")
        return

    model_info = get_model_info()
    if model_info:
        st.markdown("### ü§ñ Infos mod√®le")
        col_m1, col_m2, col_m3 = st.columns(3)
        col_m1.metric("Nom", model_info.get("model_name", "N/A"))
        col_m2.metric("Version", model_info.get("version", "N/A"))
        col_m3.metric("Date", model_info.get("training_date") or "N/A")
        col_m4, col_m5, col_m6 = st.columns(3)
        col_m4.metric("AUC", f"{model_info.get('auc', 0):.3f}" if model_info.get("auc") is not None else "N/A")
        col_m5.metric("Accuracy", f"{model_info.get('accuracy', 0):.3f}" if model_info.get("accuracy") is not None else "N/A")
        col_m6.metric("Co√ªt m√©tier", f"{model_info.get('business_cost', 0):,.0f}" if model_info.get("business_cost") is not None else "N/A")

    st.markdown("### Vue d'ensemble")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Clients", f"{len(ref_data):,}")
    with col2:
        if "TARGET" in ref_data.columns:
            st.metric("Taux d√©faut", f"{ref_data['TARGET'].mean():.1%}")
        else:
            st.metric("Taux d√©faut", "N/A")
    with col3:
        st.metric("Colonnes", f"{ref_data.shape[1]:,}")

    st.markdown("### Structure & qualit√©")
    numeric_cols = ref_data.select_dtypes(include=[np.number]).columns.tolist()
    categorical_cols = [c for c in ref_data.columns if c not in numeric_cols]
    total_cells = ref_data.shape[0] * ref_data.shape[1]
    missing_cells = int(ref_data.isna().sum().sum())
    missing_pct = (missing_cells / total_cells * 100) if total_cells else 0
    col_q1, col_q2, col_q3 = st.columns(3)
    col_q1.metric("Variables num√©riques", f"{len(numeric_cols):,}")
    col_q2.metric("Variables cat√©gorielles", f"{len(categorical_cols):,}")
    col_q3.metric("Valeurs manquantes", f"{missing_pct:.1f}%")

    if "TARGET" in ref_data.columns:
        st.markdown("### Cible (TARGET)")
        target_counts = ref_data["TARGET"].value_counts().sort_index()
        fig_target = go.Figure(
            data=[
                go.Bar(
                    x=["Non d√©faut (0)", "D√©faut (1)"],
                    y=[target_counts.get(0, 0), target_counts.get(1, 0)],
                    marker_color=["#4169E1", "#C41E3A"]
                )
            ]
        )
        fig_target.update_layout(
            height=300,
            yaxis_title="Nombre de clients",
            showlegend=False
        )
        st.plotly_chart(fig_target, use_container_width=True)

    st.markdown("---")
    st.markdown("### üí∞ Finances")
    col_f1, col_f2, col_f3 = st.columns(3)
    with col_f1:
        if "AMT_INCOME_TOTAL" in ref_data.columns:
            st.metric("Revenu m√©dian", f"{ref_data['AMT_INCOME_TOTAL'].median():,.0f}‚Ç¨")
        else:
            st.metric("Revenu m√©dian", "N/A")
    with col_f2:
        if "AMT_CREDIT" in ref_data.columns:
            st.metric("Cr√©dit m√©dian", f"{ref_data['AMT_CREDIT'].median():,.0f}‚Ç¨")
        else:
            st.metric("Cr√©dit m√©dian", "N/A")
    with col_f3:
        if "AMT_ANNUITY" in ref_data.columns:
            st.metric("Annuit√© m√©diane", f"{ref_data['AMT_ANNUITY'].median():,.0f}‚Ç¨")
        else:
            st.metric("Annuit√© m√©diane", "N/A")

    st.markdown("---")
    st.markdown("### üìä Scores externes")
    col_s1, col_s2, col_s3 = st.columns(3)
    if "EXT_SOURCE_1" in ref_data.columns:
        col_s1.metric("Score externe 1", f"{ref_data['EXT_SOURCE_1'].median():.3f}")
    else:
        col_s1.metric("Score externe 1", "N/A")
    if "EXT_SOURCE_2" in ref_data.columns:
        col_s2.metric("Score externe 2", f"{ref_data['EXT_SOURCE_2'].median():.3f}")
    else:
        col_s2.metric("Score externe 2", "N/A")
    if "EXT_SOURCE_3" in ref_data.columns:
        col_s3.metric("Score externe 3", f"{ref_data['EXT_SOURCE_3'].median():.3f}")
    else:
        col_s3.metric("Score externe 3", "N/A")

    st.markdown("---")
    st.markdown("### üìå Variables importantes")
    top_features = load_top_features_from_report(15)
    if top_features:
        display_labels = [get_feature_label(f) for f in top_features]
        st.write(", ".join(display_labels))
    else:
        st.caption("Aucune importance de feature disponible.")

    st.markdown("---")
    render_ce_checklist()

    st.markdown("---")
    st.markdown("### ‚úÖ Exigences (exigence.txt)")
    if os.path.exists(EXIGENCE_PATH):
        with st.expander("Voir toutes les exigences", expanded=False):
            try:
                with open(EXIGENCE_PATH, "r", encoding="utf-8") as f:
                    content = f.read()
                st.text(content)
            except Exception as e:
                st.error(f"Erreur de lecture: {e}")
    else:
        st.caption("Fichier exigence.txt non trouv√©.")


# ============================================
# Point d'entr√©e principal
# ============================================

def main():
    """Fonction principale de l'application."""
    st.title("üè¶ Home Credit - Outil de Scoring")
    st.markdown("""
    **Outil d'aide √† la d√©cision pour l'octroi de cr√©dit**
    
    Cette application √©value le risque de d√©faut de paiement et fournit une interpr√©tation
    claire du score pour chaque demande de cr√©dit.
    """)

    reference_data = load_reference_data()
    render_sidebar(reference_data)

    current_page = st.session_state.get("current_page", "scoring")

    if current_page == "scoring":
        render_prediction_tab()
    elif current_page == "dataset":
        render_dataset_tab()
    elif current_page == "drift":
        render_drift_tab()
    elif current_page == "docs":
        render_documentation_tab()
    else:
        st.session_state.current_page = "scoring"
        render_prediction_tab()


if __name__ == "__main__":
    main()
